{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing Unicode Strings.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOgYZBViABuMt8vDsy3p7NL"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpigYrGxUFeV"
      },
      "source": [
        "# Preprocessing Unicode Strings in TF\n",
        "\n",
        "This tutorial shows how to represent Unicode strings in TensorFlow and manipulate them using Unicode equivalents of standard string ops. It separates Unicode strings into tokens based on script detection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6tjsB_NTu6J"
      },
      "source": [
        "import tensorflow as tf \n",
        "import numpy as np "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCqAw-hEUxuT"
      },
      "source": [
        "The basic TensorFlow tf.string dtype allows you to build tensors of byte strings. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NydiOcqvUp21",
        "outputId": "c815d2b7-0644-4c5e-d375-e942e5e78bc7"
      },
      "source": [
        "tf.constant(u\"Thanks üòä\")\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=string, numpy=b'Thanks \\xf0\\x9f\\x98\\x8a'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkHvqxu4VRJG"
      },
      "source": [
        "tf.string tensor treats byte strings as atomic units. This enables it to store \n",
        "byte strings of varying lengths. The string length is not inlcuded in the \n",
        "tensor dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFU5aCKIU8rc",
        "outputId": "8aefd341-7407-4a85-fcce-cdd67df7cc51"
      },
      "source": [
        "tf.constant([u\"You're\", u\"welcome!\"]).shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF0Ey8bpVxby"
      },
      "source": [
        "## Representing Unicode \n",
        "\n",
        "There are two standard ways to represent a Unicode string in TensorFlow:\n",
        "\n",
        "string scalar ‚Äî where the sequence of code points is encoded using a known character encoding.\n",
        "int32 vector ‚Äî where each position contains a single code point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AidHW_qbVpjK",
        "outputId": "85f9f3b5-1d40-426f-afd6-ff900f67db0b"
      },
      "source": [
        "text_utf8 = tf.constant(u\"ËØ≠Ë®ÄÂ§ÑÁêÜ\")\n",
        "text_utf8"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe5\\xa4\\x84\\xe7\\x90\\x86'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCPny9tgWKZr",
        "outputId": "d9e8e631-df86-4154-e06c-993a4e34d600"
      },
      "source": [
        "text_utf16be = tf.constant(u\"ËØ≠Ë®ÄÂ§ÑÁêÜ\".encode(\"UTF-16_BE\"))\n",
        "text_utf16be"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=string, numpy=b'\\x8b\\xed\\x8a\\x00Y\\x04t\\x06'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31fXhljtWt5P",
        "outputId": "9d2e5afe-a4cd-43e9-fd60-e994356d5672"
      },
      "source": [
        "# now unicode string, represented as a vector of Unicode code points.\n",
        "\n",
        "text_chars = tf.constant([ord(char) for char in u\"ËØ≠Ë®ÄÂ§ÑÁêÜ\" ])\n",
        "text_chars"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([35821, 35328, 22788, 29702], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWozaeMlXOQH"
      },
      "source": [
        "For each character, the codes revealed\n",
        "\n",
        "## Converting between representations\n",
        "TensorFlow provides operations to convert between these different representations:\n",
        "\n",
        "tf.strings.unicode_decode: Converts an encoded string scalar to a vector of code points.\n",
        "tf.strings.unicode_encode: Converts a vector of code points to an encoded string scalar.\n",
        "tf.strings.unicode_transcode: Converts an encoded string scalar to a different encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eryVdeHtXIQr",
        "outputId": "76c7a511-c06a-41e9-e830-e2b0033066ee"
      },
      "source": [
        "tf.strings.unicode_decode(text_utf8,\n",
        "                          input_encoding = 'UTF-8')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([35821, 35328, 22788, 29702], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl-I5jcGXEFo",
        "outputId": "a0b39a9a-48e1-4408-e9bd-173a138a869e"
      },
      "source": [
        "tf.strings.unicode_encode(text_chars,\n",
        "                          output_encoding = 'UTF-8')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe5\\xa4\\x84\\xe7\\x90\\x86'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kyspx0p3ZKpl",
        "outputId": "ff23f1b1-89b0-4932-f94f-daee17f7cdb6"
      },
      "source": [
        "tf.strings.unicode_transcode(text_utf8,\n",
        "                             input_encoding = 'UTF-8',\n",
        "                             output_encoding = 'UTF-16-BE')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=string, numpy=b'\\x8b\\xed\\x8a\\x00Y\\x04t\\x06'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZK81EezZvww"
      },
      "source": [
        "## Batch dimensions\n",
        "When decoding multiple strings, the number of characters in each string may not be equal. The return result is a tf.RaggedTensor, where the innermost dimension length varies depending on the number of characters in each string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn6e2No6ZcXb",
        "outputId": "2e372ecf-7016-4f12-c7fb-915c21431f21"
      },
      "source": [
        "# A batch of Unicode strings, each represented as a UTF8-encoded string.\n",
        "batch_utf8 = [s.encode('UTF-8') for s in\n",
        "              [u'h√Éllo', u'What is the weather tomorrow', u'G√∂√∂dnight', u'üòä']]\n",
        "batch_chars_ragged = tf.strings.unicode_decode(batch_utf8,\n",
        "                                               input_encoding='UTF-8')\n",
        "for sentence_chars in batch_chars_ragged.to_list():\n",
        "  print(sentence_chars)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[104, 195, 108, 108, 111]\n",
            "[87, 104, 97, 116, 32, 105, 115, 32, 116, 104, 101, 32, 119, 101, 97, 116, 104, 101, 114, 32, 116, 111, 109, 111, 114, 114, 111, 119]\n",
            "[71, 246, 246, 100, 110, 105, 103, 104, 116]\n",
            "[128522]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sF-Eg7h8cLmo"
      },
      "source": [
        "Now we will make thie 'Ragged Tensor'usable for tensorflow.\n",
        "\n",
        "We can use this tf.RaggedTensor directly, or convert it to a dense tf.Tensor with padding or a tf.SparseTensor using the methods tf.RaggedTensor.to_tensor and tf.RaggedTensor.to_sparse."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w74P_QQBcDme",
        "outputId": "771c0328-4720-41d7-d6c0-a68e162c121e"
      },
      "source": [
        "batch_chars_padded = batch_chars_ragged.to_tensor(default_value=-1)\n",
        "print(batch_chars_padded.numpy())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   104    195    108    108    111     -1     -1     -1     -1     -1\n",
            "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
            "      -1     -1     -1     -1     -1     -1     -1     -1]\n",
            " [    87    104     97    116     32    105    115     32    116    104\n",
            "     101     32    119    101     97    116    104    101    114     32\n",
            "     116    111    109    111    114    114    111    119]\n",
            " [    71    246    246    100    110    105    103    104    116     -1\n",
            "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
            "      -1     -1     -1     -1     -1     -1     -1     -1]\n",
            " [128522     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
            "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
            "      -1     -1     -1     -1     -1     -1     -1     -1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDxpaqm0czjS"
      },
      "source": [
        "There we go..Now thats ready for our mighty Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5qjQ6HIcx9Y",
        "outputId": "d604b000-81ba-4743-ff84-d077e40b9db2"
      },
      "source": [
        "# lets see how we can make it sparse \n",
        "batch_chars_sparse = batch_chars_ragged.to_sparse()\n",
        "\n",
        "nrows, ncols = batch_chars_sparse.dense_shape.numpy()\n",
        "elements = [['_' for i in range(ncols)] for j in range(nrows)]\n",
        "for (row, col), value in zip(batch_chars_sparse.indices.numpy(), batch_chars_sparse.values.numpy()):\n",
        "  elements[row][col] = str(value)\n",
        "# max_width = max(len(value) for row in elements for value in row)\n",
        "value_lengths = []\n",
        "for row in elements:\n",
        "  for value in row:\n",
        "    value_lengths.append(len(value))\n",
        "max_width = max(value_lengths)\n",
        "print('[%s]' % '\\n '.join(\n",
        "    '[%s]' % ', '.join(value.rjust(max_width) for value in row)\n",
        "    for row in elements))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   104,    195,    108,    108,    111,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _]\n",
            " [    87,    104,     97,    116,     32,    105,    115,     32,    116,    104,    101,     32,    119,    101,     97,    116,    104,    101,    114,     32,    116,    111,    109,    111,    114,    114,    111,    119]\n",
            " [    71,    246,    246,    100,    110,    105,    103,    104,    116,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _]\n",
            " [128522,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3svlTvL3fyXa"
      },
      "source": [
        "When encoding multiple strings with the same lengths, use a tf.tensor as \n",
        "the input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKEKuq8PfwTt",
        "outputId": "b29af348-a8a9-445d-bb65-1e80f8d8c0e4"
      },
      "source": [
        "tf.strings.unicode_encode([[99, 97, 116], [100, 111, 103], [99, 111, 119]],\n",
        "                          output_encoding='UTF-8')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'cat', b'dog', b'cow'], dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXNPSGYvgxhE"
      },
      "source": [
        "When encoding multiple strings with varying length, use a tf.RaggedTensor as the input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEKjevWOgLcQ",
        "outputId": "e1595910-59f1-47f0-ad55-0afd8fa49d67"
      },
      "source": [
        "tf.strings.unicode_encode(batch_chars_ragged, output_encoding='UTF-8')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=string, numpy=\n",
              "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
              "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EK594XachAH2"
      },
      "source": [
        "If you have a tensor with multiple strings in padded or sparse format, convert it first into a tf.RaggedTensor before calling tf.strings.unicode_encode."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbS-Zxu6hAg6",
        "outputId": "76250d31-1732-4795-e8c7-93c483b86e2d"
      },
      "source": [
        "tf.strings.unicode_encode(\n",
        "    tf.RaggedTensor.from_sparse(batch_chars_sparse),\n",
        "    output_encoding = 'UTF-8'\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=string, numpy=\n",
              "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
              "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cewUB9vFhlrN",
        "outputId": "28694d44-c451-49a0-9f67-78508533740b"
      },
      "source": [
        "tf.strings.unicode_encode(\n",
        "    tf.RaggedTensor.from_tensor(batch_chars_padded, padding=-1),\n",
        "    output_encoding='UTF-8')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=string, numpy=\n",
              "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
              "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa8H60tEhhwX"
      },
      "source": [
        "## Unicode operations\n",
        "Character length\n",
        "\n",
        "Use the unit parameter of the tf.strings.length op to indicate how character lengths should be computed. unit defaults to \"BYTE\", but it can be set to other values, such as \"UTF8_CHAR\" or \"UTF16_CHAR\", to determine the number of Unicode codepoints in each encoded string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iasuKmnh3EC",
        "outputId": "39635090-fac0-4686-fe85-ca8d0540616f"
      },
      "source": [
        "# mentioning character length computation is important \n",
        "\n",
        "thanks = u'Thanks üòä '.encode('UTF-8')\n",
        "num_bytes = tf.strings.length(thanks).numpy()\n",
        "\n",
        "num_chars = tf.strings.length(thanks, unit = 'UTF8_CHAR').numpy()\n",
        "\n",
        "print('{} bytes: {} UTF-8 characters'.format(num_bytes, num_chars))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12 bytes: 9 UTF-8 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdHhaaeVkStD"
      },
      "source": [
        "## Character substring\n",
        "\n",
        "The tf.strings.substr op accepts the unit parameter, and uses it to determine what kind of offsets the pos and len paremeters contain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsyOJRqOkPVE",
        "outputId": "7daa8aff-dec5-4d76-864a-b37073f62507"
      },
      "source": [
        "tf.strings.substr(thanks, pos = 7, len = 1).numpy()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'\\xf0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hglE-vO3k5Ur",
        "outputId": "118d9441-218f-404a-a923-a904b7069692"
      },
      "source": [
        "# Specifying unit='UTF8_CHAR', returns a single 4 byte character in this case\n",
        "print(tf.strings.substr(thanks, pos=7, len=1, unit='UTF8_CHAR').numpy())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'\\xf0\\x9f\\x98\\x8a'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0x5t8Mq6lDpN"
      },
      "source": [
        "## Split unicode strings \n",
        "\n",
        "The tf.strings.unicode_split operation splits unicode strings into substrings of individual characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arfwVitclB0r",
        "outputId": "52aef4ab-0606-47c6-e0a6-6c6b186975d5"
      },
      "source": [
        "tf.strings.unicode_split(thanks, 'UTF-8').numpy()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'T', b'h', b'a', b'n', b'k', b's', b' ', b'\\xf0\\x9f\\x98\\x8a',\n",
              "       b' '], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swCCIUsrl3p2"
      },
      "source": [
        "## Byte offsets for characters\n",
        "To align the character tensor generated by tf.strings.unicode_decode with the original string, it's useful to know the offset for where each character begins. The method tf.strings.unicode_decode_with_offsets is similar to unicode_decode, except that it returns a second tensor containing the start offset of each character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJcssbbIlrND",
        "outputId": "55687259-8241-4611-a3db-f5e9da3144ca"
      },
      "source": [
        "codepoints, offsets = tf.strings.unicode_decode_with_offsets(u'üéàüéâüéä', 'UTF-8')\n",
        "\n",
        "for (codepoint, offset) in zip(codepoints.numpy(), offsets.numpy()):\n",
        "  print('At byte offset {}: codepoint {}'.format(offset, codepoint))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "At byte offset 0: codepoint 127880\n",
            "At byte offset 4: codepoint 127881\n",
            "At byte offset 8: codepoint 127882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2BajifTnVN_"
      },
      "source": [
        "## Unicode scripts\n",
        "Each Unicode code point belongs to a single collection of codepoints known as a script . A character's script is helpful in determining which language the character might be in. For example, knowing that '–ë' is in Cyrillic script indicates that modern text containing that character is likely from a Slavic language such as Russian or Ukrainian.\n",
        "\n",
        "TensorFlow provides the tf.strings.unicode_script operation to determine which script a given codepoint uses. The script codes are int32 values corresponding to International Components for Unicode (ICU) UScriptCode values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQcPX7t9muQg",
        "outputId": "8612979c-c9c4-4df4-dc28-fcc6d178eb4b"
      },
      "source": [
        "uscript = tf.strings.unicode_script([33464, 1041])\n",
        "\n",
        "print(uscript.numpy())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[17  8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te7QoBxxomFr"
      },
      "source": [
        "The tf.strings.unicode_script operation can also be applied to multidimensional tf.Tensors or tf.RaggedTensors of codepoints:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lwX6jC_nk0M",
        "outputId": "15a16d6d-fde2-4129-c1d1-dfb8b732d3b6"
      },
      "source": [
        "print(tf.strings.unicode_script(batch_chars_ragged))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.RaggedTensor [[25, 25, 25, 25, 25], [25, 25, 25, 25, 0, 25, 25, 0, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 25], [25, 25, 25, 25, 25, 25, 25, 25, 25], [0]]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SO2c36RHptjH"
      },
      "source": [
        "## Example: Simple segmentation\n",
        "Segmentation is the task of splitting text into word-like units. This is often easy when space characters are used to separate words, but some languages (like Chinese and Japanese) do not use spaces, and some languages (like German) contain long compounds that must be split in order to analyze their meaning. In web text, different languages and scripts are frequently mixed together, as in \"NYÊ†™‰æ°\" (New York Stock Exchange).\n",
        "\n",
        "We can perform very rough segmentation (without implementing any ML models) by using changes in script to approximate word boundaries. This will work for strings like the \"NYÊ†™‰æ°\" example above. It will also work for most languages that use spaces, as the space characters of various scripts are all classified as USCRIPT_COMMON, a special script code that differs from that of any actual text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4IkHuqAongh"
      },
      "source": [
        "sentence_textx = [u'Hello, world.', u'Êó•Êú¨Ë™û']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41pH67syqeng"
      },
      "source": [
        "First, decode the sentences into character codepoints, and find the script identifeir for each character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obHPWd4cqZ0q",
        "outputId": "a2aeb41c-e049-4ef1-aa3c-4140b3959970"
      },
      "source": [
        "sentence_char_codepoint = tf.strings.unicode_decode(sentence_textx,\n",
        "                                                    'UTF-8')\n",
        "print(sentence_char_codepoint)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.RaggedTensor [[72, 101, 108, 108, 111, 44, 32, 119, 111, 114, 108, 100, 46], [26085, 26412, 35486]]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5SGl7QMq1XC",
        "outputId": "37d28cc1-b0d5-4854-b055-7fa7317a1aa6"
      },
      "source": [
        "sentence_char_script = tf.strings.unicode_script(sentence_char_codepoint)\n",
        "print(sentence_char_script)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.RaggedTensor [[25, 25, 25, 25, 25, 0, 0, 25, 25, 25, 25, 25, 0], [17, 17, 17]]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmJGWsOfrQDs"
      },
      "source": [
        "Use the script identifiers to determine where word boundaries should be added. Add a word boundary at the beginning of each sentence, and for each character whose script differs from the previous character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGnKGSP5rK76",
        "outputId": "85a69058-ecf8-4910-b9cf-b6cce7916005"
      },
      "source": [
        "sentence_char_starts_word = tf.concat(\n",
        "    [tf.fill([sentence_char_script.nrows(),1], True), \n",
        "     tf.not_equal(sentence_char_script[:,1:], sentence_char_script[:, :-1])],\n",
        "    axis = 1\n",
        ")\n",
        "\n",
        "word_starts = tf.squeeze(tf.where(sentence_char_starts_word.values),axis = 1)\n",
        "print(word_starts)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([ 0  5  7 12 13], shape=(5,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_P8iFAPtWf2"
      },
      "source": [
        "You can then use those start offsets to build a RaggedTensor containing the list of words from all batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz3C3NZtsq3x",
        "outputId": "54acc409-219b-49e5-a4f0-c5775a8b910a"
      },
      "source": [
        "word_char_codepoint = tf.RaggedTensor.from_row_starts(\n",
        "    values = sentence_char_codepoint.values,\n",
        "    row_starts = word_starts\n",
        ")\n",
        "\n",
        "print(word_char_codepoint)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.RaggedTensor [[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46], [26085, 26412, 35486]]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uORzJoqIt3Ad"
      },
      "source": [
        "To finish, segment the word codepoints RaggedTensor back into sentences and encode into UTF-8 strings for readability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8dU-cAQtoea",
        "outputId": "76301d93-da23-465a-d1c9-d3d8366ebfdb"
      },
      "source": [
        "sentence_num_words = tf.reduce_sum(\n",
        "    tf.cast(sentence_char_starts_word, tf.int64), axis =1\n",
        ")\n",
        "\n",
        "sentence_word_char_codepoint = tf.RaggedTensor.from_row_lengths(\n",
        "  values = word_char_codepoint,\n",
        "  row_lengths = sentence_num_words\n",
        ")\n",
        "\n",
        "print(sentence_word_char_codepoint)\n",
        "\n",
        "tf.strings.unicode_encode(sentence_word_char_codepoint, 'UTF-8').to_list()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.RaggedTensor [[[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46]], [[26085, 26412, 35486]]]>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[b'Hello', b', ', b'world', b'.'], [b'\\xe6\\x97\\xa5\\xe6\\x9c\\xac\\xe8\\xaa\\x9e']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANBpex34u_5E"
      },
      "source": [
        "After all the preprocessing, we can understand that tensorflow has its specific way to handle with unicode and there are lots of options to play with unicode to make them TNESORFLOW ready. "
      ]
    }
  ]
}