{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Save And Load Models Using A  Distributed Strategy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO9hGQijxDoJ/hZnMagwx5j"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a6b8a703fe0c4e42bea9263dce6dd022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b17f777da3144fed934110911e6b39b0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_504efff513ad49a7b6542527bd012523",
              "IPY_MODEL_111907129fe447439a395141dcb04fda"
            ]
          }
        },
        "b17f777da3144fed934110911e6b39b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "504efff513ad49a7b6542527bd012523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5c842cfca1214416a47ff5c21a40459c",
            "_dom_classes": [],
            "description": "Dl Completed...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a25b7d5b6a24a7dbec25116d7e90f09"
          }
        },
        "111907129fe447439a395141dcb04fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8e05f0f4e13d444e853fc8e67f470c10",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [00:01&lt;00:00,  3.66 file/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a7fd95b0d9c43ee958cd14d4e643655"
          }
        },
        "5c842cfca1214416a47ff5c21a40459c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a25b7d5b6a24a7dbec25116d7e90f09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e05f0f4e13d444e853fc8e67f470c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a7fd95b0d9c43ee958cd14d4e643655": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R36j4UjMAkbz"
      },
      "source": [
        "# Save and load a model using a distributed strategy\n",
        "\n",
        "There are two sets of APIs for saving and loading model in Keras - High level, low level. This tutorial demonstrates how we can use SavedModel APIs when using tf.distribute.strategy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BdTBGq8AeSz"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9QXERraBlP6"
      },
      "source": [
        "Prepare the data and model using tf.distribute.strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDCjSt4FBjXf",
        "outputId": "7e495c1e-5916-4e62-85cf-2dfd22208f57"
      },
      "source": [
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "def get_data():\n",
        "  datasets, ds_info = tfds.load( name = 'mnist', with_info = True, as_supervised = True)\n",
        "  mnist_train, mnist_test = datasets['train'], datasets [ 'test']\n",
        "\n",
        "  BUFFER_SIZE = 10000\n",
        "\n",
        "  BATCH_SIZE_PER_REPLICA = 64\n",
        "  BATCH_SIZE = BATCH_SIZE_PER_REPLICA*mirrored_strategy.num_replicas_in_sync\n",
        "\n",
        "  def scale(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image /= 255\n",
        "\n",
        "    return image, label\n",
        "\n",
        "  train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "  eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)\n",
        "\n",
        "  return train_dataset, eval_dataset\n",
        "\n",
        "def get_model():\n",
        "  with mirrored_strategy.scope():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(10)\n",
        "                                 \n",
        "    ])\n",
        "\n",
        "    model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits= True),\n",
        "                  optimizer = tf.keras.optimizers.Adam(),\n",
        "                  metrics = [tf.metrics.SparseCategoricalAccuracy()]\n",
        "                  )\n",
        "    return model \n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324,
          "referenced_widgets": [
            "a6b8a703fe0c4e42bea9263dce6dd022",
            "b17f777da3144fed934110911e6b39b0",
            "504efff513ad49a7b6542527bd012523",
            "111907129fe447439a395141dcb04fda",
            "5c842cfca1214416a47ff5c21a40459c",
            "3a25b7d5b6a24a7dbec25116d7e90f09",
            "8e05f0f4e13d444e853fc8e67f470c10",
            "5a7fd95b0d9c43ee958cd14d4e643655"
          ]
        },
        "id": "T9TI-EAwEpOc",
        "outputId": "f68ecd49-e5fa-4468-cde4-8fc4e2ed2113"
      },
      "source": [
        "#train the model \n",
        "\n",
        "model = get_model()\n",
        "train_dataset, eval_dataset = get_data()\n",
        "model.fit(train_dataset, epochs = 2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead pass\n",
            "`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6b8a703fe0c4e42bea9263dce6dd022",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Dl Completed...', max=4.0, style=ProgressStyle(descriptioâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n",
            "Epoch 1/2\n",
            "938/938 [==============================] - 34s 32ms/step - loss: 0.2047 - sparse_categorical_accuracy: 0.9396\n",
            "Epoch 2/2\n",
            "938/938 [==============================] - 24s 26ms/step - loss: 0.0718 - sparse_categorical_accuracy: 0.9781\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1e66e9e450>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofwHwcRxE_oL"
      },
      "source": [
        "## Save and load the model \n",
        "\n",
        "Now that you have a simple model to work with, let's take a look at the saving/loading APIs. There are two sets of APIs available:\n",
        "\n",
        "High level keras model.save and tf.keras.models.load_model\n",
        "Low level tf.saved_model.save and tf.saved_model.load\n",
        "\n",
        "## The Keras APIs \n",
        "\n",
        "Here is an example of saving and loading a model with the Keras APIs:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRLKjTMhE8iK",
        "outputId": "1b4b40cb-42d5-4854-a91b-fefdc23fcb6b"
      },
      "source": [
        "keras_model_path = \"/tmp/keras_save\"\n",
        "model.save(keras_model_path)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/keras_save/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/keras_save/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNSFrmSVF2VS"
      },
      "source": [
        "Reloading the model without tf.distribute.Strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq16GZjRFqEg",
        "outputId": "9046549d-4d50-4f43-922f-8ebc257ad361"
      },
      "source": [
        "restored_keras_model = tf.keras.models.load_model(keras_model_path)\n",
        "restored_keras_model.fit(train_dataset, epochs = 2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "938/938 [==============================] - 24s 25ms/step - loss: 0.0514 - sparse_categorical_accuracy: 0.9845\n",
            "Epoch 2/2\n",
            "938/938 [==============================] - 23s 25ms/step - loss: 0.0359 - sparse_categorical_accuracy: 0.9889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1e65eb0d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYZIKcfxHY0w"
      },
      "source": [
        "After restoring the model, you can continue training on it, even without needing to call compile() again, since it is already compiled before saving. The model is saved in the TensorFlow's standard SavedModel proto format.\n",
        "\n",
        "Lets load the model and train it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p38QOUNZGJoI",
        "outputId": "8d779212-b6a8-4212-b770-a9452dbc86f1"
      },
      "source": [
        "another_strategy = tf.distribute.OneDeviceStrategy(\"/cpu:0\")\n",
        "with another_strategy.scope():\n",
        "  restored_keras_model_ds = tf.keras.models.load_model(keras_model_path)\n",
        "  restored_keras_model_ds.fit(train_dataset, epochs=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "938/938 [==============================] - 24s 25ms/step - loss: 0.0505 - sparse_categorical_accuracy: 0.9849\n",
            "Epoch 2/2\n",
            "938/938 [==============================] - 24s 25ms/step - loss: 0.0349 - sparse_categorical_accuracy: 0.9891\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCXVOmbnIV30"
      },
      "source": [
        "## tf.saved_model APIs\n",
        "Lets take a look at the lower level APIs. Saving the model is similar to the keras API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vaIqUBhH-AZ",
        "outputId": "6c544a97-9b92-404c-e7fe-d442d431dd23"
      },
      "source": [
        "model = get_model()\n",
        "saved_model_path = \"/tmp/tf_save\"\n",
        "tf.saved_model.save(model, saved_model_path)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tf_save/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tf_save/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbTTJrvhK0ZT"
      },
      "source": [
        "Loading can be done with tf.saved_model.load(). However, since it is an API that is on the lower level (and hence has a wider range of use cases), it does not return a Keras model. Instead, it returns an object that contain functions that can be used to do inference. For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzOx5Pl4JGof"
      },
      "source": [
        "DEFAULT_FUNCTION_KEY = \"serving_default\"\n",
        "loaded = tf.saved_model.load(saved_model_path)\n",
        "inference_func = loaded.signatures[DEFAULT_FUNCTION_KEY]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihbGqAL0MF6c"
      },
      "source": [
        "The loaded object may contain multiple functions, each associated with a key. The \"serving_default\" is the default key for the inference function with a saved Keras model. To do an inference with this function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyMe2X0fLQ4M",
        "outputId": "b66eec04-79e8-471f-9a18-6711d6ec7d2b"
      },
      "source": [
        "predict_dataset = eval_dataset.map(lambda image,label: image)\n",
        "for batch in predict_dataset.take(1):\n",
        "  print(inference_func(batch))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'dense_3': <tf.Tensor: shape=(64, 10), dtype=float32, numpy=\n",
            "array([[ 6.33138046e-02, -3.60530466e-02, -1.09878458e-01,\n",
            "        -1.35206953e-01,  1.17276855e-01, -5.08575886e-02,\n",
            "         1.64591402e-01,  1.48164248e-03,  3.06673627e-02,\n",
            "        -1.16027847e-01],\n",
            "       [ 6.24670349e-02, -5.81023619e-02, -3.23682614e-02,\n",
            "        -1.79502115e-01, -5.37753571e-03, -4.24278937e-02,\n",
            "         1.50196269e-01,  2.15451270e-02, -5.42667992e-02,\n",
            "         2.01064870e-02],\n",
            "       [ 4.65019681e-02, -1.52240157e-01, -1.21094733e-01,\n",
            "        -3.47707756e-02, -6.38998896e-02, -8.08315575e-02,\n",
            "         2.70212144e-01, -1.73431300e-02, -4.92041111e-02,\n",
            "         4.08092588e-02],\n",
            "       [ 8.67107660e-02,  9.40914266e-03, -1.97490290e-01,\n",
            "        -7.65941814e-02, -5.37231565e-02,  2.91546136e-02,\n",
            "         2.18398899e-01,  7.45067792e-03,  3.97551368e-04,\n",
            "         2.76662838e-02],\n",
            "       [-8.11396465e-02, -6.86105266e-02, -1.76406965e-01,\n",
            "        -1.25270575e-01,  3.70395295e-02, -2.49482617e-02,\n",
            "         1.23737216e-01, -6.21923944e-03,  1.39501154e-01,\n",
            "        -6.95530102e-02],\n",
            "       [ 1.28364161e-01, -4.39283960e-02, -3.23170006e-01,\n",
            "        -1.70068040e-01,  1.29288644e-01, -4.72450256e-02,\n",
            "         2.09656343e-01,  5.78186810e-02,  8.78215360e-04,\n",
            "        -3.10653355e-03],\n",
            "       [ 1.38489977e-01, -3.90088409e-02, -1.28598571e-01,\n",
            "        -2.42112890e-01,  1.05834924e-01, -6.58536553e-02,\n",
            "         5.16466424e-02,  1.02960333e-01, -4.05227989e-02,\n",
            "         2.99753379e-02],\n",
            "       [ 3.79971340e-02, -7.42707625e-02, -1.99981451e-01,\n",
            "        -7.93396458e-02, -2.62580626e-03,  2.04444993e-02,\n",
            "         2.00913891e-01, -5.50465891e-03, -2.11353451e-02,\n",
            "        -2.16932353e-02],\n",
            "       [ 2.07603589e-01,  3.54469940e-03, -2.33464450e-01,\n",
            "        -1.35124743e-01, -1.12703191e-02,  1.64225288e-02,\n",
            "         2.48122960e-01, -2.16132924e-02, -1.15781486e-01,\n",
            "        -8.84375796e-02],\n",
            "       [ 1.17354356e-01,  1.02214612e-01, -4.79982309e-02,\n",
            "        -1.09669141e-01, -2.86032483e-02,  4.73788865e-02,\n",
            "         8.93439129e-02, -6.09467104e-02, -7.01691359e-02,\n",
            "        -1.11533567e-01],\n",
            "       [ 1.22785725e-01, -8.05028155e-02, -1.24333754e-01,\n",
            "        -5.64018227e-02, -1.24857001e-01, -5.06270491e-02,\n",
            "         2.86627233e-01, -3.52874063e-02, -3.99221592e-02,\n",
            "         3.01912837e-02],\n",
            "       [ 1.38054237e-01,  9.79208294e-03, -2.16028363e-01,\n",
            "        -2.52403498e-01, -4.58162278e-02, -9.17979404e-02,\n",
            "         2.39914149e-01,  3.77573185e-02, -5.46567552e-02,\n",
            "        -5.30651361e-02],\n",
            "       [-6.20944239e-02, -4.52138670e-02, -1.72724336e-01,\n",
            "        -8.25308710e-02, -3.90890986e-03, -5.16439043e-03,\n",
            "         1.19338483e-01, -2.88297087e-02, -3.12629044e-02,\n",
            "        -5.76857962e-02],\n",
            "       [ 3.49579230e-02, -4.65837978e-02, -3.02603990e-01,\n",
            "        -2.05463067e-01,  5.20809591e-02, -6.69750571e-02,\n",
            "         2.68836170e-01,  1.99419390e-02, -6.44251890e-03,\n",
            "        -3.56651917e-02],\n",
            "       [ 1.60497010e-01,  1.22534260e-02, -3.14666867e-01,\n",
            "        -1.62019774e-01,  1.02567375e-02,  3.48696038e-02,\n",
            "         1.67846695e-01,  4.48894575e-02, -7.39615271e-03,\n",
            "         2.16859505e-02],\n",
            "       [-3.99916321e-02, -8.74393061e-02, -2.55710304e-01,\n",
            "        -3.00485957e-02,  1.80942252e-01, -3.28885354e-02,\n",
            "         1.50589526e-01,  5.91468140e-02,  2.14578398e-02,\n",
            "         5.86348474e-02],\n",
            "       [ 5.26185110e-02, -4.49674167e-02, -2.21811175e-01,\n",
            "        -1.39865115e-01,  9.34710074e-03, -6.37545213e-02,\n",
            "         2.05780268e-01, -3.90170477e-02,  2.16759834e-03,\n",
            "        -6.21960424e-02],\n",
            "       [ 7.77048916e-02,  7.12460726e-02, -1.91216171e-01,\n",
            "        -2.06141815e-01,  1.26205301e-02, -2.82819699e-02,\n",
            "         2.22545952e-01, -1.79139394e-02, -6.29332289e-02,\n",
            "        -7.60267526e-02],\n",
            "       [ 4.80093062e-02, -5.25921397e-02, -1.56208456e-01,\n",
            "        -1.38821959e-01, -3.32781151e-02, -3.73608917e-02,\n",
            "         2.25784689e-01, -4.35952768e-02, -4.26547378e-02,\n",
            "        -7.37013444e-02],\n",
            "       [ 1.71735995e-02, -9.20196995e-02, -2.93565750e-01,\n",
            "        -8.39828104e-02, -2.95638796e-02,  9.27055106e-02,\n",
            "         2.18289539e-01,  8.74696448e-02,  6.11800216e-02,\n",
            "        -7.26656243e-02],\n",
            "       [ 6.61602914e-02,  3.68154645e-02, -1.80033997e-01,\n",
            "        -7.81386197e-02,  1.03966326e-01, -8.53491798e-02,\n",
            "         1.16498627e-01, -1.38460407e-02, -5.25035560e-02,\n",
            "        -8.03794190e-02],\n",
            "       [ 1.35705575e-01,  4.50784527e-02, -1.06025763e-01,\n",
            "        -8.45733806e-02, -1.00876754e-02,  1.44798814e-05,\n",
            "         2.38686904e-01, -2.35238448e-02, -4.07091528e-02,\n",
            "        -4.59470823e-02],\n",
            "       [ 1.31255731e-01,  8.92699063e-02, -1.39910638e-01,\n",
            "        -2.25226268e-01,  6.43097088e-02, -1.14184655e-02,\n",
            "         1.11932449e-01, -6.14328124e-02, -3.73893753e-02,\n",
            "        -5.01343571e-02],\n",
            "       [ 5.11249248e-03, -3.94111723e-02, -7.31696039e-02,\n",
            "        -2.26821586e-01,  3.57043222e-02, -7.14168847e-02,\n",
            "         6.84962198e-02, -1.88478250e-02,  3.53907757e-02,\n",
            "        -6.30543828e-02],\n",
            "       [ 1.33108303e-01,  1.09584667e-02, -1.74753234e-01,\n",
            "        -1.41847983e-01,  2.16911593e-03, -4.33863737e-02,\n",
            "         1.54043317e-01, -7.94069320e-02, -8.67705941e-02,\n",
            "        -5.73051870e-02],\n",
            "       [ 1.31908864e-01,  6.34482428e-02, -1.48720637e-01,\n",
            "        -2.00194761e-01, -2.08053575e-03, -1.17032072e-02,\n",
            "         2.35600978e-01,  1.84787624e-02, -1.07709050e-01,\n",
            "        -1.00605302e-01],\n",
            "       [ 5.91783598e-02, -3.34721468e-02, -1.47423819e-01,\n",
            "        -1.25840515e-01,  1.54376607e-02, -9.31093120e-04,\n",
            "         1.08252607e-01, -4.00570557e-02, -5.68646677e-02,\n",
            "        -4.73801680e-02],\n",
            "       [ 1.08882887e-02, -7.78975934e-02, -2.46737629e-01,\n",
            "        -1.98121503e-01,  1.01361223e-01, -1.97266459e-01,\n",
            "         1.78315043e-01, -1.39418691e-02,  2.03499161e-02,\n",
            "         7.50951618e-02],\n",
            "       [-7.32582584e-02, -2.58722510e-02, -1.02204166e-01,\n",
            "        -1.21853575e-01,  1.91320125e-02, -6.26019994e-03,\n",
            "         9.64644924e-02, -5.66082783e-02,  5.58664054e-02,\n",
            "         1.02543347e-02],\n",
            "       [ 5.37707321e-02, -1.07034795e-01, -2.09257692e-01,\n",
            "        -7.53080100e-02,  9.52910725e-03, -6.57907128e-02,\n",
            "         2.53695726e-01, -4.59273867e-02, -3.60016190e-02,\n",
            "         2.47115642e-02],\n",
            "       [ 7.98388198e-02, -8.75112489e-02, -2.21609429e-01,\n",
            "        -1.64993301e-01, -9.64022125e-04, -9.86830443e-02,\n",
            "         2.61575222e-01,  4.93199490e-02,  2.25965306e-02,\n",
            "        -5.62743656e-02],\n",
            "       [ 1.16287872e-01, -3.49682793e-02, -7.97568783e-02,\n",
            "        -1.17073655e-01, -1.35090828e-01,  3.31892706e-02,\n",
            "         2.00189710e-01, -9.39170942e-02, -7.18619600e-02,\n",
            "        -1.76463827e-01],\n",
            "       [ 1.29995123e-01, -2.11264640e-02, -2.86010921e-01,\n",
            "        -2.01589525e-01, -5.28840162e-02,  3.59399728e-02,\n",
            "         2.93453395e-01, -1.65140294e-02, -1.65150166e-01,\n",
            "        -5.95402382e-02],\n",
            "       [ 6.40297383e-02,  3.18121724e-03, -1.51255399e-01,\n",
            "        -1.23479322e-01,  7.34388456e-02, -1.47322835e-02,\n",
            "         1.51021808e-01,  4.67958599e-02, -1.26211275e-03,\n",
            "        -1.11306779e-01],\n",
            "       [ 1.45148352e-01, -3.65176238e-02, -1.41512066e-01,\n",
            "        -2.14373305e-01,  4.68446221e-03, -6.07162062e-03,\n",
            "         1.90812826e-01,  1.15517648e-02, -5.19629456e-02,\n",
            "        -6.06820621e-02],\n",
            "       [-4.48346846e-02, -1.12265393e-01, -1.00975461e-01,\n",
            "        -2.62905043e-02, -5.75131215e-02, -6.62688464e-02,\n",
            "         2.05284461e-01,  3.34412158e-02,  3.49233299e-02,\n",
            "         4.68700081e-02],\n",
            "       [ 1.08103804e-01,  5.36654964e-02, -1.55062601e-02,\n",
            "        -9.79137719e-02, -6.49570953e-03,  1.00335935e-02,\n",
            "         2.04909667e-01,  9.97817889e-03, -2.25193053e-02,\n",
            "        -1.89180613e-01],\n",
            "       [ 2.33545378e-02, -8.99173617e-02, -2.70323455e-01,\n",
            "        -1.57760233e-01,  5.62961074e-03, -8.46477896e-02,\n",
            "         2.12857142e-01, -2.04586107e-02, -3.07036657e-02,\n",
            "         5.59744202e-02],\n",
            "       [ 4.56777327e-02, -1.45002408e-02, -1.28810063e-01,\n",
            "        -5.01998886e-02,  3.59669328e-02, -4.31621261e-02,\n",
            "         1.32959768e-01,  5.41221946e-02,  1.55541040e-02,\n",
            "        -1.08175032e-01],\n",
            "       [ 7.80806094e-02, -5.11100441e-02, -1.87828884e-01,\n",
            "        -1.34058356e-01, -5.53578548e-02,  3.05964332e-02,\n",
            "         1.63757488e-01, -4.91297990e-02, -8.15337300e-02,\n",
            "         5.94219677e-02],\n",
            "       [ 5.55963553e-02, -1.24713637e-01, -2.40930632e-01,\n",
            "        -1.73154011e-01, -1.00562563e-02,  1.35818124e-01,\n",
            "         1.39393374e-01,  1.09085165e-01, -1.08440727e-01,\n",
            "        -6.31895661e-02],\n",
            "       [-3.10268402e-02, -5.89579567e-02, -2.17760816e-01,\n",
            "        -9.34268609e-02,  2.34708022e-02, -5.21071954e-03,\n",
            "         1.76723778e-01, -1.97691731e-02, -7.81028857e-03,\n",
            "         4.25011702e-02],\n",
            "       [ 1.18771866e-02, -3.89736407e-02, -2.14217469e-01,\n",
            "        -5.55759706e-02,  2.00847350e-02, -3.17244120e-02,\n",
            "         1.94267407e-01, -2.45375820e-02, -8.31092745e-02,\n",
            "         8.13926850e-03],\n",
            "       [ 5.34930155e-02, -1.37880340e-01, -1.77839652e-01,\n",
            "        -8.59389082e-02,  2.74131894e-02, -5.43260388e-02,\n",
            "         1.76155418e-01, -6.11453950e-02, -1.19547304e-02,\n",
            "        -1.25474975e-01],\n",
            "       [ 6.54959753e-02, -4.45258170e-02, -1.72193021e-01,\n",
            "        -1.05825983e-01,  8.92483518e-02, -2.51919571e-02,\n",
            "         2.40256250e-01,  1.70351062e-02,  4.33502123e-02,\n",
            "         7.57741556e-02],\n",
            "       [ 1.66264266e-01,  2.46849209e-02, -1.05733380e-01,\n",
            "        -5.32719828e-02, -9.63149220e-02,  3.07921339e-02,\n",
            "         2.04243556e-01, -8.81187469e-02, -9.64932889e-02,\n",
            "        -1.13352671e-01],\n",
            "       [ 3.98759469e-02, -1.85297579e-02, -2.27847591e-01,\n",
            "        -1.32210165e-01,  1.44582894e-02, -4.36542928e-02,\n",
            "         1.29500419e-01, -3.46388705e-02, -1.36941765e-02,\n",
            "        -9.51128379e-02],\n",
            "       [ 8.17002058e-02, -4.26309295e-02, -2.31251791e-01,\n",
            "        -2.91317523e-01,  5.58288544e-02, -1.17662087e-01,\n",
            "         1.05499901e-01,  8.74282196e-02, -1.17903315e-01,\n",
            "         1.21415548e-01],\n",
            "       [ 7.01054484e-02, -4.97058220e-02, -3.37300271e-01,\n",
            "        -1.17683329e-01, -3.60524692e-02,  8.17881972e-02,\n",
            "         1.72730014e-01,  1.45902997e-02, -6.27691522e-02,\n",
            "        -1.01417333e-01],\n",
            "       [ 2.66033132e-02,  2.68240273e-02, -1.42572060e-01,\n",
            "        -2.72802748e-02, -6.31462634e-02,  6.86205253e-02,\n",
            "         1.67016044e-01, -7.21959248e-02, -4.64754105e-02,\n",
            "        -3.80565040e-02],\n",
            "       [ 6.63491786e-02,  3.67307290e-02, -1.28898025e-01,\n",
            "        -1.42945409e-01,  2.05024108e-02, -5.97112300e-03,\n",
            "         1.25230238e-01,  6.74367100e-02, -3.94617952e-02,\n",
            "        -2.72235759e-02],\n",
            "       [-5.60386404e-02, -5.63736260e-03, -1.36823803e-01,\n",
            "        -8.03591311e-02, -6.46021068e-02, -1.66779030e-02,\n",
            "         1.13193609e-01, -4.58558351e-02,  2.90850680e-02,\n",
            "        -1.15361057e-01],\n",
            "       [-1.50498040e-02,  1.23176258e-02, -2.36364260e-01,\n",
            "        -1.15504988e-01,  2.65111923e-02, -5.09768277e-02,\n",
            "         1.20549895e-01, -2.78443284e-02, -8.12871382e-02,\n",
            "        -2.08867155e-02],\n",
            "       [ 5.98149654e-03, -7.56528303e-02, -1.70766145e-01,\n",
            "        -1.29957095e-01,  4.96192388e-02, -4.91941199e-02,\n",
            "         1.11203909e-01, -2.51421761e-02,  7.31570064e-04,\n",
            "        -6.70305490e-02],\n",
            "       [ 4.91091460e-02, -9.37912911e-02, -2.44549185e-01,\n",
            "        -1.30459040e-01,  1.11315623e-01, -9.39854160e-02,\n",
            "         2.29346246e-01,  2.19924003e-03,  3.59552503e-02,\n",
            "        -5.13691753e-02],\n",
            "       [ 1.17928132e-01,  3.92647041e-03, -2.68628418e-01,\n",
            "        -1.61180824e-01,  8.77766982e-02, -1.70452192e-01,\n",
            "         2.71843016e-01,  4.40471284e-02, -1.28038123e-01,\n",
            "         1.10607073e-01],\n",
            "       [ 6.04132265e-02, -3.72234322e-02, -8.09760243e-02,\n",
            "        -1.61903039e-01,  5.20921648e-02,  7.07647763e-03,\n",
            "         1.49899036e-01,  8.63645300e-02,  2.18719728e-02,\n",
            "        -1.41177207e-01],\n",
            "       [ 1.52815981e-02, -5.70456907e-02, -2.70081699e-01,\n",
            "        -1.37932837e-01, -4.58071344e-02,  3.20784375e-02,\n",
            "         2.38708705e-01, -4.10975143e-02, -8.06968138e-02,\n",
            "        -7.08137378e-02],\n",
            "       [ 1.16891697e-01, -9.98975709e-02, -2.88950473e-01,\n",
            "        -9.11745057e-02,  1.16122244e-02,  7.24723712e-02,\n",
            "         1.80145353e-01,  1.30330756e-01, -2.57152542e-02,\n",
            "         4.51101214e-02],\n",
            "       [ 8.32593068e-02, -3.39242406e-02, -1.84655376e-02,\n",
            "        -1.14252299e-01, -1.05740258e-03, -2.09658802e-01,\n",
            "         3.36920708e-01, -2.31626630e-02,  6.94735628e-03,\n",
            "         1.12951696e-01],\n",
            "       [ 4.87619974e-02, -5.86890876e-02, -2.04753786e-01,\n",
            "        -9.51501802e-02,  5.44158667e-02, -4.63017002e-02,\n",
            "         1.89164892e-01,  2.91787367e-02, -8.45830292e-02,\n",
            "        -1.84156396e-03],\n",
            "       [ 1.17081612e-01, -1.18963428e-01, -2.49265611e-01,\n",
            "        -1.77435979e-01,  7.21627101e-02, -7.18416944e-02,\n",
            "         1.83121577e-01,  3.15373950e-02,  2.42340639e-02,\n",
            "        -1.63516365e-02],\n",
            "       [ 6.96115894e-03, -6.04782663e-02, -3.05399328e-01,\n",
            "        -1.37077123e-01,  1.04528196e-01, -2.70345155e-02,\n",
            "         1.36382997e-01,  4.62372452e-02,  3.15537564e-02,\n",
            "         3.92560139e-02],\n",
            "       [ 1.86035544e-01, -1.87129565e-02, -1.39980093e-01,\n",
            "        -5.75499088e-02,  1.12488844e-01, -7.30197579e-02,\n",
            "         1.37307435e-01,  5.98119199e-03, -5.77441826e-02,\n",
            "        -7.54096359e-02]], dtype=float32)>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsWCi8DmOsnK"
      },
      "source": [
        "You can also load and do inference in a distributed manner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qerx0hwpOCCc",
        "outputId": "d122c09e-43c8-40fa-a3ca-a5088645a79d"
      },
      "source": [
        "another_strategy = tf.distribute.MirroredStrategy()\n",
        "with another_strategy.scope():\n",
        "  loaded = tf.saved_model.load(saved_model_path)\n",
        "  inference_func = loaded.signatures[DEFAULT_FUNCTION_KEY]\n",
        "\n",
        "  dist_predict_dataset = another_strategy.experimental_distribute_dataset(\n",
        "      predict_dataset\n",
        "  )\n",
        "\n",
        "  # calling for function in a distributed manner \n",
        "\n",
        "  for batch in dist_predict_dataset:\n",
        "    another_strategy.run(inference_func, args = (batch,))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFRNMcnwWrSo"
      },
      "source": [
        "Calling the restored function is just a forward pass on the saved model (predict). What if yout want to continue training the loaded function? Or embed the loaded function into a bigger model? A common practice is to wrap this loaded object to a Keras layer to achieve this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIIgU3ocP63w",
        "outputId": "aa6e5625-1216-45d4-ddc1-da9249cde31e"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "def build_model(loaded):\n",
        "  x = tf.keras.layers.Input(shape = (28, 28, 1), name = 'input_x')\n",
        "  # Wrap what's loaded to a KerasLayer\n",
        "\n",
        "  keras_layer = hub.KerasLayer(loaded, trainable = True)(x)\n",
        "  model = tf.keras.Model(x, keras_layer)\n",
        "  return model \n",
        "\n",
        "another_strategy = tf.distribute.MirroredStrategy()\n",
        "with another_strategy.scope():\n",
        "  loaded = tf.saved_model.load(saved_model_path)\n",
        "  model = build_model(loaded)\n",
        "\n",
        "  model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits= True),\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [tf.metrics.SparseCategoricalAccuracy()])\n",
        "  model.fit(train_dataset, epochs = 2)\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "938/938 [==============================] - 27s 26ms/step - loss: 0.2157 - sparse_categorical_accuracy: 0.9368\n",
            "Epoch 2/2\n",
            "938/938 [==============================] - 25s 26ms/step - loss: 0.0715 - sparse_categorical_accuracy: 0.9786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puI_UgE9aXYq"
      },
      "source": [
        "As you can see, hub.KerasLayer wraps the result loaded back from tf.saved_model.load() into a Keras layer that can be used to build another model. This is very useful for transfer learning.\n",
        "\n",
        "It is possible to mix and match the APIs. You can save a Keras model with model.save, and load a non-Keras model with the low-level API, tf.saved_model.load."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5hm_QGgZOrY",
        "outputId": "4e52e384-21e9-40d4-bcf7-57ccee91e00a"
      },
      "source": [
        "model = get_model()\n",
        "\n",
        "# saving the model using keras' save() API \n",
        "model.save(keras_model_path)\n",
        "\n",
        "another_strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "# Loading the model using lower level api\n",
        "\n",
        "with another_strategy.scope():\n",
        "  loaded = tf.saved_model.load(keras_model_path)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/keras_save/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/keras_save/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJA6GsxKcdQt"
      },
      "source": [
        "## Saving/Loading from local device \n",
        "\n",
        "When saving and loading from a local io device while running remotely, for example using a cloud TPU, the option experimental_io_device must be used to set the io device to localhost."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXv5nng2cVxw",
        "outputId": "343991ef-1764-4496-f901-124ee8948215"
      },
      "source": [
        "model = get_model()\n",
        "\n",
        "# saving the model to a path on localhost\n",
        "\n",
        "saved_model_path = \"/tmp/tf_save\"\n",
        "save_options = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
        "model.save(saved_model_path, options = save_options)\n",
        "\n",
        "# loading the model from a path on a localhost.\n",
        "another_strategy = tf.distribute.MirroredStrategy()\n",
        "with another_strategy.scope():\n",
        "  load_options = tf.saved_model.LoadOptions(experimental_io_device= '/job:localhost')\n",
        "  loaded = tf.keras.models.load_model(saved_model_path, options= load_options)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tf_save/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tf_save/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "no_trzise82X"
      },
      "source": [
        "## Caveats \n",
        "\n",
        "A special case is when you have a Keras model that does not have well-defined inputs. For example, a Sequential model can be created without any input shapes (Sequential([Dense(3), ...]). Subclassed models also do not have well-defined inputs after initialization. In this case, you should stick with the lower level APIs on both saving and loading, otherwise you will get an error.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwEAOpMTeUdU",
        "outputId": "cd97f3d2-cb9c-4e51-bdf7-b09053bcce98"
      },
      "source": [
        "class SubclassedModel(tf.keras.Model):\n",
        "\n",
        "  output_name = 'output_layer'\n",
        "\n",
        "  def __init__(self):\n",
        "    super(SubclassedModel, self).__init__()\n",
        "    self._dense_layer = tf.keras.layers.Dense(\n",
        "        5, dtype= tf.dtypes.float32, name = self.output_name\n",
        "    )\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return self._dense_layer(inputs)\n",
        "\n",
        "my_model = SubclassedModel()\n",
        "\n",
        "tf.saved_model.save(my_model, saved_model_path)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.SubclassedModel object at 0x7f1e66c3aa50>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.SubclassedModel object at 0x7f1e66c3aa50>, because it is not built.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f1e66d44190>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f1e66d44190>, because it is not built.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tf_save/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tf_save/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq-gb5yIha97"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}