{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Loading and Saving A Model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM3qFggjIi+8uv1FLQZulas",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farsim-hossain/python-projects/blob/main/Loading_and_Saving_A_Model_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RN6fDesScjEP"
      },
      "source": [
        "# Loading and Saving Model \n",
        "\n",
        "In this exercise, we will learn how to load and save models in TF \n",
        "\n",
        "There is a dependency for saving a model in HDFS format. That is called pyyaml h5py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqH39TzqcoIU",
        "outputId": "a294ef25-d60d-4046-f2e8-0e21a1194a2d"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.version.VERSION)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8vIR-FTdRqG"
      },
      "source": [
        "## Get an example Dataset \n",
        "\n",
        "To demonstrate how er load and train weights, we will use MNIST dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKDSzeU6dKFV"
      },
      "source": [
        "(train_images, train_labels), (test_images,test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "train_labels = train_labels[:1000] # just getting 1000 samples to make the process shorter\n",
        "test_labels = test_labels[:1000]\n",
        "\n",
        "train_images = train_images[:1000].reshape(-1, 28*28)/255.0 \n",
        "test_images = test_images[:1000].reshape(-1, 28*28)/255.0\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nygOxvp0fMkH"
      },
      "source": [
        "## Defining a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9jNJv12fHuA",
        "outputId": "e2e86305-e9ae-4113-ca33-7321accbe5fb"
      },
      "source": [
        "def create_model():\n",
        "  model = tf.keras.models.Sequential([\n",
        "                                      keras.layers.Dense(512, activation='relu', input_shape = (784,)),\n",
        "                                      keras.layers.Dropout(0.2),\n",
        "                                      keras.layers.Dense(10)\n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "      optimizer = 'adam',\n",
        "      loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      metrics = [tf.metrics.SparseCategoricalAccuracy()]\n",
        "  )\n",
        "\n",
        "  return model\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v5QZ4LXgYj_"
      },
      "source": [
        "## Save checkpoints during training\n",
        "\n",
        "You can use a trained model without having to retrain it, or pick-up training where you left off in case the training process was interrupted. The tf.keras.callbacks.ModelCheckpoint callback allows you to continually save the model both during and at the end of training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcSkNkCQgPww",
        "outputId": "e6c265f1-e460-469b-e505-6636c24978ee"
      },
      "source": [
        "checkpoint_path = \"training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Creating a callback that saves the model's weights \n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose= 1)\n",
        "\n",
        "# train the model with new callback \n",
        "\n",
        "model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    epochs = 10,\n",
        "    validation_data = (test_images, test_labels),\n",
        "    callbacks = [cp_callback]\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.6042 - sparse_categorical_accuracy: 0.4845 - val_loss: 0.7348 - val_sparse_categorical_accuracy: 0.7760\n",
            "\n",
            "Epoch 00001: saving model to training_1/cp.ckpt\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.4456 - sparse_categorical_accuracy: 0.8796 - val_loss: 0.5392 - val_sparse_categorical_accuracy: 0.8280\n",
            "\n",
            "Epoch 00002: saving model to training_1/cp.ckpt\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.2970 - sparse_categorical_accuracy: 0.9210 - val_loss: 0.4879 - val_sparse_categorical_accuracy: 0.8520\n",
            "\n",
            "Epoch 00003: saving model to training_1/cp.ckpt\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.2160 - sparse_categorical_accuracy: 0.9404 - val_loss: 0.4736 - val_sparse_categorical_accuracy: 0.8530\n",
            "\n",
            "Epoch 00004: saving model to training_1/cp.ckpt\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1658 - sparse_categorical_accuracy: 0.9649 - val_loss: 0.4300 - val_sparse_categorical_accuracy: 0.8640\n",
            "\n",
            "Epoch 00005: saving model to training_1/cp.ckpt\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1195 - sparse_categorical_accuracy: 0.9776 - val_loss: 0.4021 - val_sparse_categorical_accuracy: 0.8690\n",
            "\n",
            "Epoch 00006: saving model to training_1/cp.ckpt\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0891 - sparse_categorical_accuracy: 0.9889 - val_loss: 0.3999 - val_sparse_categorical_accuracy: 0.8690\n",
            "\n",
            "Epoch 00007: saving model to training_1/cp.ckpt\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0658 - sparse_categorical_accuracy: 0.9941 - val_loss: 0.3932 - val_sparse_categorical_accuracy: 0.8690\n",
            "\n",
            "Epoch 00008: saving model to training_1/cp.ckpt\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0545 - sparse_categorical_accuracy: 0.9934 - val_loss: 0.4204 - val_sparse_categorical_accuracy: 0.8690\n",
            "\n",
            "Epoch 00009: saving model to training_1/cp.ckpt\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0455 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.3998 - val_sparse_categorical_accuracy: 0.8700\n",
            "\n",
            "Epoch 00010: saving model to training_1/cp.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2b806c5b50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKaN2uothilp"
      },
      "source": [
        "Now we can see a checkpoint location and what is inside it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YIW7b_kiCab",
        "outputId": "1a0e5e74-e045-4c78-867c-eec765e31bf8"
      },
      "source": [
        "os.listdir(checkpoint_dir)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cp.ckpt.data-00000-of-00001', 'checkpoint', 'cp.ckpt.index']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttyTWrNliXX-"
      },
      "source": [
        "## Recalling weights from another model \n",
        "As long as two models share the same architecture you can share weights between them. So, when restoring a model from weights-only, create a model with the same architecture as the original model and then set its weights.\n",
        "\n",
        "Lets check with a new untrained model which might give a 10% accuracy, doesnt matter. We will update the model with our trained model weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTmgp1LdiG6O",
        "outputId": "353bc7f8-d9f9-4cad-8254-b5044733d965"
      },
      "source": [
        "model = create_model()\n",
        "\n",
        "#evaluate the model \n",
        "\n",
        "loss, acc = model.evaluate(test_images, test_labels, verbose = 2)\n",
        "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 - 0s - loss: 2.3111 - sparse_categorical_accuracy: 0.1670\n",
            "Untrained model, accuracy: 16.70%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRwjIKYWjhYw"
      },
      "source": [
        "## Loading the weights and reevaluate the model \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrdaAOZhjl4N",
        "outputId": "fe7c71cc-2130-4240-add5-655a82aff3ae"
      },
      "source": [
        "model.load_weights(checkpoint_path)\n",
        "\n",
        "loss,acc = model.evaluate(test_images, test_labels, verbose = 2)\n",
        "print(\"Restored model, accuracy:{:5.2f}\".format(100*acc))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 - 0s - loss: 0.3998 - sparse_categorical_accuracy: 0.8700\n",
            "Restored model, accuracy:87.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PugZpq6OkNdg"
      },
      "source": [
        "## Checkpoints saving options with different names\n",
        "\n",
        "The callback provides several options to provide unique names for checkpoints and adjust the checkpointing frequency.\n",
        "\n",
        "Train a new model, and save uniquely named checkpoints once every five epochs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRgkaIc2j5Nm",
        "outputId": "2f78812a-d6fc-40ca-e830-402243b86b99"
      },
      "source": [
        "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "#new callback that saves the model's weights every 5 epochs\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    save_freq=5*batch_size) # the important takeaway\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "# Save the weights using the `checkpoint_path` format\n",
        "\n",
        "model.save_weights(checkpoint_path.format(epoch=0))\n",
        "\n",
        "\n",
        "# train with new callback \n",
        "\n",
        "model.fit(train_images, \n",
        "          train_labels,\n",
        "          epochs=50, \n",
        "          batch_size=batch_size, \n",
        "          callbacks=[cp_callback],\n",
        "          validation_data=(test_images, test_labels),\n",
        "          verbose=0)\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00005: saving model to training_2/cp-0005.ckpt\n",
            "\n",
            "Epoch 00010: saving model to training_2/cp-0010.ckpt\n",
            "\n",
            "Epoch 00015: saving model to training_2/cp-0015.ckpt\n",
            "\n",
            "Epoch 00020: saving model to training_2/cp-0020.ckpt\n",
            "\n",
            "Epoch 00025: saving model to training_2/cp-0025.ckpt\n",
            "\n",
            "Epoch 00030: saving model to training_2/cp-0030.ckpt\n",
            "\n",
            "Epoch 00035: saving model to training_2/cp-0035.ckpt\n",
            "\n",
            "Epoch 00040: saving model to training_2/cp-0040.ckpt\n",
            "\n",
            "Epoch 00045: saving model to training_2/cp-0045.ckpt\n",
            "\n",
            "Epoch 00050: saving model to training_2/cp-0050.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2b7dea5ad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo5_KyZdnaep"
      },
      "source": [
        "## Checking the list of checkpoints again "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNf5KXDDmyrI",
        "outputId": "5b7b511d-d153-4650-c588-ae1b85d57552"
      },
      "source": [
        "os.listdir(checkpoint_dir)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cp-0050.ckpt.index',\n",
              " 'cp-0010.ckpt.index',\n",
              " 'cp-0030.ckpt.index',\n",
              " 'cp-0040.ckpt.index',\n",
              " 'cp-0035.ckpt.data-00000-of-00001',\n",
              " 'cp-0025.ckpt.index',\n",
              " 'checkpoint',\n",
              " 'cp-0025.ckpt.data-00000-of-00001',\n",
              " 'cp-0015.ckpt.data-00000-of-00001',\n",
              " 'cp-0045.ckpt.index',\n",
              " 'cp-0015.ckpt.index',\n",
              " 'cp-0000.ckpt.data-00000-of-00001',\n",
              " 'cp-0020.ckpt.index',\n",
              " 'cp-0035.ckpt.index',\n",
              " 'cp-0045.ckpt.data-00000-of-00001',\n",
              " 'cp-0020.ckpt.data-00000-of-00001',\n",
              " 'cp-0005.ckpt.data-00000-of-00001',\n",
              " 'cp-0050.ckpt.data-00000-of-00001',\n",
              " 'cp-0000.ckpt.index',\n",
              " 'cp-0005.ckpt.index',\n",
              " 'cp-0040.ckpt.data-00000-of-00001',\n",
              " 'cp-0010.ckpt.data-00000-of-00001',\n",
              " 'cp-0030.ckpt.data-00000-of-00001']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVbOzo1Tn0A6"
      },
      "source": [
        "## Getting the latest checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VNxrFwh3nhCm",
        "outputId": "ed394192-6d43-4df6-ebbd-b300e0678d38"
      },
      "source": [
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "latest"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'training_2/cp-0050.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-Ee1zVZoCb3"
      },
      "source": [
        "## To test, reset the model and loading the latest checkpoint \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ro8S3TObn7nn",
        "outputId": "c79c4b82-1107-4949-8bfd-1a3debbde234"
      },
      "source": [
        "model = create_model()\n",
        "\n",
        "model.load_weights(latest)\n",
        "\n",
        "loss ,acc = model.evaluate(test_images, test_labels, verbose =2)\n",
        "print(\"Restored model, accuracy : {:5.2f}%\".format(100*acc))\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 - 0s - loss: 0.4799 - sparse_categorical_accuracy: 0.8790\n",
            "Restored model, accuracy : 87.90%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r653ETVLo8tI"
      },
      "source": [
        "## Manually Save Weights \n",
        "\n",
        "Manually saving weights with the Model.save_weights method. By default, tf.keras—and save_weights in particular—uses the TensorFlow checkpoint format with a .ckpt extension (saving in HDF5 with a .h5 extension is covered in the Save and serialize models guide)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIT-SEAuoq7M",
        "outputId": "668b5f0c-f5a8-45c9-d786-bea27fc676b9"
      },
      "source": [
        "#save weights \n",
        "\n",
        "model.save_weights('./checkpoints/my_checkpoint')\n",
        "\n",
        "#Create a new model instance \n",
        "model = create_model()\n",
        "\n",
        "#restore the weights\n",
        "model.load_weights('./checkpoints/my_checkpoint')\n",
        "\n",
        "# evaluate the model \n",
        "loss,acc = model.evaluate(test_images, test_labels, verbose =2)\n",
        "print(\"Restored model, accuracy:{:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 - 0s - loss: 0.4799 - sparse_categorical_accuracy: 0.8790\n",
            "Restored model, accuracy:87.90%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzNAoIQNqY8Y"
      },
      "source": [
        "## Save the entire model \n",
        "\n",
        "Call model.save to save a model's architecture, weights, and training configuration in a single file/folder. This allows you to export a model so it can be used without access to the original Python code*. Since the optimizer-state is recovered, you can resume training from exactly where you left off.\n",
        "\n",
        "An entire model can be saved in two different file formats (SavedModel and HDF5). The TensorFlow SavedModel format is the default file format in TF2.x. However, models can be saved in HDF5 format. More details on saving entire models in the two file formats is described below.\n",
        "\n",
        "Saving a fully-functional model is very useful—you can load them in TensorFlow.js (Saved Model, HDF5) and then train and run them in web browsers, or convert them to run on mobile devices using TensorFlow Lite (Saved Model, HDF5)\n",
        "\n",
        "*Custom objects (e.g. subclassed models or layers) require special attention when saving and loading. See the Saving custom objects section below\n",
        "\n",
        "## SavedModel format \n",
        "\n",
        "The SavedModel format is another way to serialize models. Models saved in this format can be restored using tf.keras.models.load_model and are compatible with TensorFlow Serving. The SavedModel guide goes into detail about how to serve/inspect the SavedModel. The section below illustrates the steps to save and restore the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvEbRQkhqHun",
        "outputId": "27dad923-2c2f-492b-cf71-0708006d78ca"
      },
      "source": [
        "## example create and train a new model instance \n",
        "\n",
        "model = create_model()\n",
        "model.fit(train_images, train_labels, epochs= 5)\n",
        "\n",
        "## Save the entire model as a saved model \n",
        "\n",
        "!mkdir -p saved_model\n",
        "model.save('saved_model/my_model')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "32/32 [==============================] - 1s 5ms/step - loss: 1.6237 - sparse_categorical_accuracy: 0.4784\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.4476 - sparse_categorical_accuracy: 0.8769\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.2833 - sparse_categorical_accuracy: 0.9236\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.2274 - sparse_categorical_accuracy: 0.9328\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1901 - sparse_categorical_accuracy: 0.9629\n",
            "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lm45Y7uVs9ZB"
      },
      "source": [
        "The SavedModel format is a directory containing a protobuf binary and a Tensorflow checkpoint. Inspect the saved model directory: \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoH5nrSBs4hd",
        "outputId": "0d1e424e-5cda-4afc-d8e9-6af3b0ed0182"
      },
      "source": [
        "!ls saved_model"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bPUK_1YuIFe",
        "outputId": "c7b44aa1-24cb-4efb-800a-cea7e38422cd"
      },
      "source": [
        "!ls saved_model/my_model"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "assets\tsaved_model.pb\tvariables\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBejRwi8uSit"
      },
      "source": [
        "## Lets reload a fresh keras model and load opur model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4YcA149uM8m",
        "outputId": "fb60bf06-5e66-48c1-a720-67f35ae04ec4"
      },
      "source": [
        "new_model = tf.keras.models.load_model('saved_model/my_model')\n",
        "\n",
        "new_model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CztqQIpKuk5V"
      },
      "source": [
        "The restored model is compiled with the same arguments as the original model. Try running evaluate and predict with the loaded model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xT0wj7rnueYt",
        "outputId": "ad51c9d6-a55b-4d14-d858-490866e6e437"
      },
      "source": [
        "loss, acc = new_model.evaluate(test_images, test_labels, verbose =2)\n",
        "\n",
        "print('Restored model, accuracy: {:5.2f}%'.format(100*acc))\n",
        "\n",
        "print(new_model.predict(test_images).shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 - 0s - loss: 0.4523 - sparse_categorical_accuracy: 0.8420\n",
            "Restored model, accuracy: 84.20%\n",
            "(1000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUN9LhnyvFd5"
      },
      "source": [
        "## HDF5 Format\n",
        "\n",
        "There is another way to save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13XPYyXvvDDX",
        "outputId": "5fc41884-e576-4fb5-b5e2-e6d2d3437037"
      },
      "source": [
        "model = create_model()\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "model.save('my_model.h5')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 1.6517 - sparse_categorical_accuracy: 0.4784\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5075 - sparse_categorical_accuracy: 0.8718\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.3233 - sparse_categorical_accuracy: 0.9182\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.2289 - sparse_categorical_accuracy: 0.9480\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1661 - sparse_categorical_accuracy: 0.9583\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OgUhj1_vbvv"
      },
      "source": [
        "Lets recrate the model from this file\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yM2bpqfvWrW",
        "outputId": "8ce74f31-dd2b-4e3d-d7d2-f94fd02f2f54"
      },
      "source": [
        "new_model = tf.keras.models.load_model('my_model.h5')\n",
        "\n",
        "new_model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_14 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtOy05PPvoY-",
        "outputId": "d25a8af8-5905-49be-ec51-35c052ffecb0"
      },
      "source": [
        "# accuracy check \n",
        "\n",
        "loss, acc = new_model.evaluate(test_images, test_labels, verbose = 2)\n",
        "\n",
        "print(\"Restored model , accuracy: {:5.2f}\".format(100*acc))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 - 0s - loss: 0.4209 - sparse_categorical_accuracy: 0.8720\n",
            "Restored model , accuracy: 87.20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAlVVNbdwfr2"
      },
      "source": [
        "Keras saves models by inspecting their architectures. This technique saves everything:\n",
        "\n",
        "The weight values\n",
        "The model's architecture\n",
        "The model's training configuration (what you pass to the .compile() method)\n",
        "The optimizer and its state, if any (this enables you to restart training where you left off)\n",
        "Keras is not able to save the v1.x optimizers (from tf.compat.v1.train) since they aren't compatible with checkpoints. For v1.x optimizers, you need to re-compile the model after loading—losing the state of the optimizer."
      ]
    }
  ]
}