{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hypertuning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMj1q0rqUSrnHB2O+yg+7Ft",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farsim-hossain/python-projects/blob/main/Hypertuning%20With%20Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKHBtq-Ldqwc"
      },
      "source": [
        "# Hyperparameter Tuning With Keras \n",
        "\n",
        "We will use Keras tuner to perform hypertuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmYIyH2Dd4S0"
      },
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow import keras "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARVmehyRd9a4",
        "outputId": "1711d9e5-17d8-4845-f942-bc7f586b1af3"
      },
      "source": [
        "pip install -q -U keras-tuner"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█████▏                          | 10kB 19.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 25.6MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30kB 26.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40kB 20.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51kB 10.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 61kB 11.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 6.4MB/s \n",
            "\u001b[?25h  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjCtZykoeDAU"
      },
      "source": [
        "import kerastuner as kt \n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AymNGpwmevwA"
      },
      "source": [
        "## Loading the dataset \n",
        "\n",
        "We will use the fashion mnist dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xHLmyo0etNe",
        "outputId": "3f2e0339-be68-4015-b466-9b36b6329081"
      },
      "source": [
        "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1_mQM88fDjh"
      },
      "source": [
        "## Normalizing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONXbmZmue_3i"
      },
      "source": [
        "img_train = img_train.astype('float32')/255.0\n",
        "img_test = img_test.astype('float32')/255.0"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWMFUDMSfREM"
      },
      "source": [
        "## Defining the model \n",
        "\n",
        "When you build a model for hypertuning, you also define the hyperparameter search space in addition to the model architecture. The model you set up for hypertuning is called a hypermodel.\n",
        "\n",
        "You can define a hypermodel through two approaches:\n",
        "\n",
        "By using a model builder function\n",
        "By subclassing the HyperModel class of the Keras Tuner API\n",
        "\n",
        "In this tutorial, you use a model builder function to define the image classification model. The model builder function returns a compiled model and uses hyperparameters you define inline to hypertune the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUPZRKRDfPzE"
      },
      "source": [
        "def model_builder(hp):\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "\n",
        "  # Tune the number of units in the first Dense layer\n",
        "  # Choose an optimal value between 32-512\n",
        "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
        "  model.add(keras.layers.Dense(10))\n",
        "\n",
        "  # Tune the learning rate for the optimizer\n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAyQJ1-Oj2DQ"
      },
      "source": [
        "## Instantiate the tuner and perform hyper tuning\n",
        "\n",
        "We will use Hyperband tuner. To instantiate the Hyperband tuner, you must specify the hypermodel, the objective to optimize and the maximum number of epochs to train (max_epochs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwqmfPUJjUs_"
      },
      "source": [
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='intro_to_kt')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO_YKe5ymVZR"
      },
      "source": [
        "## Early Stopping \n",
        "\n",
        "hyperband algorithm uses adaptive resources allocation and early stopping to quickly converge on a high performing model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2a95faikh8P"
      },
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience =5)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhpVR9kwnJDE"
      },
      "source": [
        "Now we have the hyperband ready which takes the model in its arguements, we have the early stopping ready. Now lets search the hyperparameters.\n",
        "\n",
        "**The Search method is the method that will RUN the search of the tuner object**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4qN8zN7m2z_",
        "outputId": "1a9d50ec-4d9e-48e1-9628-8780fc47535b"
      },
      "source": [
        "tuner.search(img_train, label_train, epochs = 50, validation_split = 0.2, callbacks = [stop_early])\n",
        "\n",
        "# get the optimal hyper parameters \n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 30 Complete [00h 00m 26s]\n",
            "val_accuracy: 0.8559166789054871\n",
            "\n",
            "Best val_accuracy So Far: 0.8877500295639038\n",
            "Total elapsed time: 00h 07m 31s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "\n",
            "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
            "layer is 384 and the optimal learning rate for the optimizer\n",
            "is 0.001.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ozPUGbUqkZh"
      },
      "source": [
        "## Train The model \n",
        "\n",
        "Find the optimal number of epochs to train the model with the hyperparameters obtained from the search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ni6NV3gcpflr",
        "outputId": "ff83dbbc-5b80-44e8-b85e-2d073e848510"
      },
      "source": [
        "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs \n",
        "\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "# noe fitting the model \n",
        "history = model.fit(img_train, label_train, epochs = 50, validation_split = 0.2)\n",
        "# finding the best epoch\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch))+1\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.6325 - accuracy: 0.7750 - val_loss: 0.4162 - val_accuracy: 0.8448\n",
            "Epoch 2/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3817 - accuracy: 0.8619 - val_loss: 0.3903 - val_accuracy: 0.8581\n",
            "Epoch 3/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3384 - accuracy: 0.8745 - val_loss: 0.3811 - val_accuracy: 0.8622\n",
            "Epoch 4/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3055 - accuracy: 0.8880 - val_loss: 0.3547 - val_accuracy: 0.8738\n",
            "Epoch 5/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2862 - accuracy: 0.8923 - val_loss: 0.3671 - val_accuracy: 0.8693\n",
            "Epoch 6/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2687 - accuracy: 0.9000 - val_loss: 0.3138 - val_accuracy: 0.8876\n",
            "Epoch 7/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2541 - accuracy: 0.9040 - val_loss: 0.3178 - val_accuracy: 0.8864\n",
            "Epoch 8/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2388 - accuracy: 0.9102 - val_loss: 0.3219 - val_accuracy: 0.8866\n",
            "Epoch 9/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2315 - accuracy: 0.9134 - val_loss: 0.3163 - val_accuracy: 0.8899\n",
            "Epoch 10/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2241 - accuracy: 0.9183 - val_loss: 0.3182 - val_accuracy: 0.8856\n",
            "Epoch 11/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2069 - accuracy: 0.9217 - val_loss: 0.3159 - val_accuracy: 0.8897\n",
            "Epoch 12/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2032 - accuracy: 0.9230 - val_loss: 0.3327 - val_accuracy: 0.8849\n",
            "Epoch 13/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2025 - accuracy: 0.9247 - val_loss: 0.3134 - val_accuracy: 0.8938\n",
            "Epoch 14/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1935 - accuracy: 0.9278 - val_loss: 0.3315 - val_accuracy: 0.8916\n",
            "Epoch 15/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1825 - accuracy: 0.9312 - val_loss: 0.3475 - val_accuracy: 0.8875\n",
            "Epoch 16/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1767 - accuracy: 0.9340 - val_loss: 0.3304 - val_accuracy: 0.8928\n",
            "Epoch 17/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1730 - accuracy: 0.9342 - val_loss: 0.3374 - val_accuracy: 0.8957\n",
            "Epoch 18/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1662 - accuracy: 0.9365 - val_loss: 0.3561 - val_accuracy: 0.8851\n",
            "Epoch 19/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1598 - accuracy: 0.9403 - val_loss: 0.3353 - val_accuracy: 0.8949\n",
            "Epoch 20/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1562 - accuracy: 0.9402 - val_loss: 0.3530 - val_accuracy: 0.8878\n",
            "Epoch 21/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1485 - accuracy: 0.9441 - val_loss: 0.3475 - val_accuracy: 0.8930\n",
            "Epoch 22/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1476 - accuracy: 0.9439 - val_loss: 0.3527 - val_accuracy: 0.8946\n",
            "Epoch 23/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1463 - accuracy: 0.9443 - val_loss: 0.3684 - val_accuracy: 0.8913\n",
            "Epoch 24/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1375 - accuracy: 0.9467 - val_loss: 0.3718 - val_accuracy: 0.8938\n",
            "Epoch 25/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1335 - accuracy: 0.9499 - val_loss: 0.3879 - val_accuracy: 0.8920\n",
            "Epoch 26/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1350 - accuracy: 0.9496 - val_loss: 0.3826 - val_accuracy: 0.8930\n",
            "Epoch 27/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1271 - accuracy: 0.9517 - val_loss: 0.3753 - val_accuracy: 0.8964\n",
            "Epoch 28/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1236 - accuracy: 0.9536 - val_loss: 0.3846 - val_accuracy: 0.8929\n",
            "Epoch 29/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1189 - accuracy: 0.9551 - val_loss: 0.4017 - val_accuracy: 0.8919\n",
            "Epoch 30/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1165 - accuracy: 0.9566 - val_loss: 0.3862 - val_accuracy: 0.8974\n",
            "Epoch 31/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1109 - accuracy: 0.9582 - val_loss: 0.4011 - val_accuracy: 0.8944\n",
            "Epoch 32/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1123 - accuracy: 0.9566 - val_loss: 0.4006 - val_accuracy: 0.8984\n",
            "Epoch 33/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1050 - accuracy: 0.9603 - val_loss: 0.3964 - val_accuracy: 0.8976\n",
            "Epoch 34/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0991 - accuracy: 0.9627 - val_loss: 0.4499 - val_accuracy: 0.8919\n",
            "Epoch 35/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1054 - accuracy: 0.9604 - val_loss: 0.4157 - val_accuracy: 0.8963\n",
            "Epoch 36/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0974 - accuracy: 0.9634 - val_loss: 0.4313 - val_accuracy: 0.8907\n",
            "Epoch 37/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1047 - accuracy: 0.9609 - val_loss: 0.4432 - val_accuracy: 0.8969\n",
            "Epoch 38/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0978 - accuracy: 0.9631 - val_loss: 0.4403 - val_accuracy: 0.8948\n",
            "Epoch 39/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0925 - accuracy: 0.9660 - val_loss: 0.4457 - val_accuracy: 0.8943\n",
            "Epoch 40/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0942 - accuracy: 0.9644 - val_loss: 0.4570 - val_accuracy: 0.8906\n",
            "Epoch 41/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0851 - accuracy: 0.9684 - val_loss: 0.4623 - val_accuracy: 0.8967\n",
            "Epoch 42/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0899 - accuracy: 0.9664 - val_loss: 0.4579 - val_accuracy: 0.8940\n",
            "Epoch 43/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0845 - accuracy: 0.9679 - val_loss: 0.5083 - val_accuracy: 0.8931\n",
            "Epoch 44/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0857 - accuracy: 0.9678 - val_loss: 0.4535 - val_accuracy: 0.8959\n",
            "Epoch 45/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0769 - accuracy: 0.9717 - val_loss: 0.4676 - val_accuracy: 0.8945\n",
            "Epoch 46/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0778 - accuracy: 0.9708 - val_loss: 0.5032 - val_accuracy: 0.8945\n",
            "Epoch 47/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0821 - accuracy: 0.9697 - val_loss: 0.5067 - val_accuracy: 0.8907\n",
            "Epoch 48/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0749 - accuracy: 0.9724 - val_loss: 0.5155 - val_accuracy: 0.8893\n",
            "Epoch 49/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0743 - accuracy: 0.9724 - val_loss: 0.5149 - val_accuracy: 0.8953\n",
            "Epoch 50/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0784 - accuracy: 0.9701 - val_loss: 0.5068 - val_accuracy: 0.8916\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6cj2FXztcDl"
      },
      "source": [
        "## Retraining the model with best epoch found in the previous step "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMTKJcWUtSu1",
        "outputId": "2d0c4864-77be-4a55-8af8-93904488391a"
      },
      "source": [
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "#retraining with hte best epoch number\n",
        "hypermodel.fit(img_train, label_train, epochs = best_epoch, validation_split=0.2)\n",
        "\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/32\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.6301 - accuracy: 0.7769 - val_loss: 0.4015 - val_accuracy: 0.8562\n",
            "Epoch 2/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3750 - accuracy: 0.8654 - val_loss: 0.3635 - val_accuracy: 0.8679\n",
            "Epoch 3/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3287 - accuracy: 0.8797 - val_loss: 0.3410 - val_accuracy: 0.8760\n",
            "Epoch 4/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3112 - accuracy: 0.8858 - val_loss: 0.3448 - val_accuracy: 0.8791\n",
            "Epoch 5/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2787 - accuracy: 0.8961 - val_loss: 0.3498 - val_accuracy: 0.8748\n",
            "Epoch 6/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2727 - accuracy: 0.9003 - val_loss: 0.3385 - val_accuracy: 0.8771\n",
            "Epoch 7/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2604 - accuracy: 0.9040 - val_loss: 0.3126 - val_accuracy: 0.8873\n",
            "Epoch 8/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2478 - accuracy: 0.9066 - val_loss: 0.3373 - val_accuracy: 0.8835\n",
            "Epoch 9/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2303 - accuracy: 0.9140 - val_loss: 0.3404 - val_accuracy: 0.8781\n",
            "Epoch 10/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2298 - accuracy: 0.9138 - val_loss: 0.3175 - val_accuracy: 0.8880\n",
            "Epoch 11/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2096 - accuracy: 0.9204 - val_loss: 0.3331 - val_accuracy: 0.8879\n",
            "Epoch 12/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2115 - accuracy: 0.9195 - val_loss: 0.3313 - val_accuracy: 0.8873\n",
            "Epoch 13/32\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1970 - accuracy: 0.9253 - val_loss: 0.3275 - val_accuracy: 0.8902\n",
            "Epoch 14/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1919 - accuracy: 0.9277 - val_loss: 0.3367 - val_accuracy: 0.8897\n",
            "Epoch 15/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1829 - accuracy: 0.9317 - val_loss: 0.3402 - val_accuracy: 0.8910\n",
            "Epoch 16/32\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1747 - accuracy: 0.9342 - val_loss: 0.3372 - val_accuracy: 0.8893\n",
            "Epoch 17/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1734 - accuracy: 0.9351 - val_loss: 0.3507 - val_accuracy: 0.8867\n",
            "Epoch 18/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1658 - accuracy: 0.9387 - val_loss: 0.3550 - val_accuracy: 0.8882\n",
            "Epoch 19/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1578 - accuracy: 0.9422 - val_loss: 0.3305 - val_accuracy: 0.8978\n",
            "Epoch 20/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1567 - accuracy: 0.9399 - val_loss: 0.3490 - val_accuracy: 0.8903\n",
            "Epoch 21/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1526 - accuracy: 0.9417 - val_loss: 0.3666 - val_accuracy: 0.8924\n",
            "Epoch 22/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1422 - accuracy: 0.9463 - val_loss: 0.3680 - val_accuracy: 0.8888\n",
            "Epoch 23/32\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1382 - accuracy: 0.9488 - val_loss: 0.3971 - val_accuracy: 0.8856\n",
            "Epoch 24/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1349 - accuracy: 0.9493 - val_loss: 0.3780 - val_accuracy: 0.8928\n",
            "Epoch 25/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1355 - accuracy: 0.9478 - val_loss: 0.3633 - val_accuracy: 0.8991\n",
            "Epoch 26/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1285 - accuracy: 0.9509 - val_loss: 0.3870 - val_accuracy: 0.8908\n",
            "Epoch 27/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1304 - accuracy: 0.9508 - val_loss: 0.3754 - val_accuracy: 0.8955\n",
            "Epoch 28/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1212 - accuracy: 0.9557 - val_loss: 0.4178 - val_accuracy: 0.8918\n",
            "Epoch 29/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1180 - accuracy: 0.9551 - val_loss: 0.4170 - val_accuracy: 0.8852\n",
            "Epoch 30/32\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1117 - accuracy: 0.9584 - val_loss: 0.3929 - val_accuracy: 0.8967\n",
            "Epoch 31/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1109 - accuracy: 0.9587 - val_loss: 0.4167 - val_accuracy: 0.8917\n",
            "Epoch 32/32\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1140 - accuracy: 0.9569 - val_loss: 0.4216 - val_accuracy: 0.8934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faa03ae0050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQHsfRauvGZH"
      },
      "source": [
        "## Evaluating the hypermodel on the test data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-E77epTvA9K",
        "outputId": "da1db0d6-6a1a-4010-cb29-0281c239d96e"
      },
      "source": [
        "eval_result = hypermodel.evaluate(img_test, label_test)\n",
        "print(\"[test loss, test accuracy]:\", eval_result)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4708 - accuracy: 0.8876\n",
            "[test loss, test accuracy]: [0.47079238295555115, 0.8876000046730042]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdynyxClwXz5"
      },
      "source": [
        "# A slight overfit"
      ]
    }
  ]
}