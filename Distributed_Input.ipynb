{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Distributed Input.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOO1PoBKhs6PwgivULVKhtD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNhaaJl0NhfH"
      },
      "source": [
        "# Distributed Input\n",
        "\n",
        "tf.distribute API provvide a way for users to process the training and getting raw input in multiple machines.\n",
        "\n",
        "tf.distribute efficiently works when used with tf.data.Dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvAVSuCmM95j",
        "outputId": "33e33b9f-1f11-4f09-eccf-9e5e619e5970"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8Di1X4aO-gR",
        "outputId": "a65c2d87-73ff-4af0-a911-ab92cd29c6fb"
      },
      "source": [
        "global_batch_size = 16\n",
        "# Create a tf.data.Dataset object.\n",
        "dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(100).batch(global_batch_size)\n",
        "@tf.function\n",
        "def train_step(inputs):\n",
        "  features, labels = inputs\n",
        "  return labels - 0.3 * features\n",
        "\n",
        "# Iterate over the dataset using the for..in construct.\n",
        "for inputs in dataset:\n",
        "  print(train_step(inputs))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(4, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrMB9NCwQUMD"
      },
      "source": [
        "This API takes a tf.data.Dataset instance as input and returns a tf.distribute.DistributedDataset instance. You should batch the input dataset with a value that is equal to the global batch size. This global batch size is the number of samples that you want to process across all devices in 1 step. You can iterate over this distributed dataset in a Pythonic fashion or create an iterator using iter. The returned object is not a tf.data.Dataset instance and does not support any other APIs that transform or inspect the dataset in any way. This is the recommended API if you donâ€™t have specific ways in which you want to shard your input over different replicas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axyUK0l0Pm3i",
        "outputId": "4c3e0a1e-23ff-43a2-d35b-a1f56fa13db2"
      },
      "source": [
        "global_batch_size = 16\n",
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensors(([1.],[1.])).repeat(100).batch(global_batch_size)\n",
        "\n",
        "dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)\n",
        "\n",
        "print(next(iter(dist_dataset)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "(<tf.Tensor: shape=(16, 1), dtype=float32, numpy=\n",
            "array([[1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.]], dtype=float32)>, <tf.Tensor: shape=(16, 1), dtype=float32, numpy=\n",
            "array([[1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.]], dtype=float32)>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4bx2cABTINB"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensors(([1.],[1.])).repeat(64).batch(16)\n",
        "options = tf.data.Options()\n",
        "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n",
        "dataset = dataset.with_options(options)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RTsBhLRTJtQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f68c0c25-9b26-4e8d-d17b-a4d061b0b552"
      },
      "source": [
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "def dataset_fn(input_context):\n",
        "  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n",
        "  dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(64).batch(16)\n",
        "  dataset = dataset.shard(\n",
        "      input_context.num_input_pipelines, input_context.input_pipeline_id\n",
        "  )\n",
        "\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  dataset = dataset.prefetch(2)\n",
        "  return dataset\n",
        "\n",
        "dist_dataset = mirrored_strategy.distribute_datasets_from_function(dataset_fn)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjtXsT9jb-OR",
        "outputId": "fc13cf02-b715-4dbe-de9a-b9973460da94"
      },
      "source": [
        "global_batch_size = 16\n",
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensors(([1.],[1.])).repeat(100).batch(global_batch_size)\n",
        "\n",
        "dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)\n",
        "\n",
        "@tf.function\n",
        "def train_step(inputs):\n",
        "  features, labels = inputs \n",
        "  return labels - 0.3 * features\n",
        "\n",
        "for x in dist_dataset:\n",
        "  loss = mirrored_strategy.run(train_step, args = (x,))\n",
        "  print(\"Loss is\", loss)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(4, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R0ul90wkc8b"
      },
      "source": [
        "Iterating elements in a distributed dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQu1_Z0qkWop",
        "outputId": "bb86ccb5-64bc-45b2-f389-70f808649209"
      },
      "source": [
        "num_epochs = 10\n",
        "steps_per_epoch = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  dist_iterator = iter(dist_dataset)\n",
        "  for step in range(steps_per_epoch):\n",
        "\n",
        "    loss = mirrored_strategy.run(train_step, args = (next(dist_iterator),))\n",
        "\n",
        "    print(\"Loss is\", loss)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n",
            "Loss is tf.Tensor(\n",
            "[[0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]\n",
            " [0.7]], shape=(16, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkIXvHtEm-bY"
      },
      "source": [
        "With next() or tf.distribute.DistributedIterator.get_next(), if the tf.distribute.DistributedIterator has reached its end, an OutOfRange error will be thrown. The client can catch the error on python side and continue doing other work such as checkpointing and evaluation. However, this will not work if you are using a host training loop (i.e., run multiple steps per tf.function), which looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYJVvV-9mx6n"
      },
      "source": [
        "@tf.function\n",
        "def train_fn(iterator):\n",
        "  for _ in tf.range(steps_per_loop):\n",
        "    strategy.run(steps_fn, args = (next(iterator),))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRKQTCFln-wn",
        "outputId": "31ed82b4-fc5e-4abb-d160-e93f99f5fd20"
      },
      "source": [
        "global_batch_size = 4\n",
        "steps_per_loop = 5\n",
        "strategy = tf.distribute.MirroredStrategy(devices = [\"GPU:0\", \"CPU:0\"])\n",
        "\n",
        "dataset = tf.data.Dataset.range(9).batch(global_batch_size)\n",
        "distributed_iterator = iter(strategy.experimental_distribute_dataset(dataset))\n",
        "\n",
        "@tf.function\n",
        "def train_fn(distributed_iterator):\n",
        "  for _ in tf.range(steps_per_loop):\n",
        "    optional_data = distributed_iterator.get_next_as_optional()\n",
        "    if not optional_data.has_value():\n",
        "      break\n",
        "\n",
        "    per_replica_results = strategy.run(lambda x:x , args=(optional_data.get_value(),) )\n",
        "    tf.print(strategy.experimental_local_results(per_replica_results))\n",
        "train_fn(distributed_iterator)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:localhost/replica:0/task:0/device:CPU:0,/job:localhost/replica:0/task:0/device:GPU:0\n",
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:CPU:0')\n",
            "([0 1], [2 3])\n",
            "([4 5], [6 7])\n",
            "([8], [])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n9QZ5DxrbVx"
      },
      "source": [
        "## Using element_spec property\n",
        "\n",
        "If you pass the elements of a distributed dataset to a tf.function and want a tf.TypeSpec guarantee, you can specify the input_signature argument of the tf.function. The output of a distributed dataset is tf.distribute.DistributedValues which can represent the input to a single device or multiple devices. To get the tf.TypeSpec corresponding to this distributed value you can use the element_spec property of the distributed dataset or distributed iterator object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfh06mNnrNPb",
        "outputId": "42524535-c320-4860-8b75-c1e44b447e1a"
      },
      "source": [
        "global_batch_size = 16 \n",
        "\n",
        "epochs = 5\n",
        "steps_per_epoch = 5\n",
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensors(([1.],[1.])).repeat(100).batch(global_batch_size)\n",
        "dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)\n",
        "\n",
        "@tf.function(input_signature=[dist_dataset.element_spec])\n",
        "def train_step(per_replica_inputs):\n",
        "  def step_fn(inputs):\n",
        "    return 2 * inputs\n",
        "\n",
        "  return mirrored_strategy.run(step_fn, args = (per_replica_inputs,))\n",
        "\n",
        "for _ in range(epochs):\n",
        "  iterator = iter(dist_dataset)\n",
        "  for _ in range(steps_per_epoch):\n",
        "    output = train_step(next(iterator))\n",
        "    tf.print(output)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "([[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]])\n",
            "([[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]])\n",
            "([[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]])\n",
            "([[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]])\n",
            "([[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]])\n",
            "([[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]])\n",
            "([[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]])\n",
            "([[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]])\n",
            "([[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]])\n",
            "([[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]])\n",
            "([[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]])\n",
            "([[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]])\n",
            "([[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]])\n",
            "([[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]])\n",
            "([[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]])\n",
            "([[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]])\n",
            "([[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]])\n",
            "([[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]])\n",
            "([[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]])\n",
            "([[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]])\n",
            "([[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]])\n",
            "([[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]])\n",
            "([[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]])\n",
            "([[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]])\n",
            "([[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]], [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVvMJ3QT0oGi"
      },
      "source": [
        "If your input pipeline includes both shuffling the data on record level and parsing the data, unless the unparsed data is significantly larger than the parsed data (which is usually not the case), shuffle first and then parse, as shown in the following example. This may benefit memory usage and performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcbtnShO0hDv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "a751a171-e1fb-49a7-e5b0-56819ce16179"
      },
      "source": [
        "d = tf.data.Dataset.list_files(pattern, shuffle = False)\n",
        "d = d.shard(num_workers, worker_index)\n",
        "d = d.repeat(num_epochs)\n",
        "d = d.shuffle(shuffle_buffer_size)\n",
        "d = d.interleave(tf.data.TFRecordDataset,\n",
        "                 cycle_length = num_readers, block_length = 1)\n",
        "d = d.map(parser_fn, num_parallel_calls = num_map_threads)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-c68b6cc15893>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffle_buffer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m d = d.interleave(tf.data.TFRecordDataset,\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pattern' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG8f9jQLds5p"
      },
      "source": [
        "The order in which the data is processed by the workers when using tf.distribute.experimental_distribute_dataset or tf.distribute.distribute_datasets_from_function is not guaranteed. This is typically required if you are using tf.distribute to scale prediction. You can however insert an index for each element in the batch and order outputs accordingly. The following snippet is an example of how to order outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8Ef8FMEaKdS",
        "outputId": "6e124a18-5b52-4610-89b8-ce5868878332"
      },
      "source": [
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "dataset_size = 24\n",
        "batch_size = 6\n",
        "dataset = tf.data.Dataset.range(dataset_size).enumerate().batch(batch_size)\n",
        "dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)\n",
        "\n",
        "def predict(index, inputs):\n",
        "  outputs = 2 * inputs\n",
        "  return index, outputs\n",
        "\n",
        "result = {}\n",
        "for index, inputs in dist_dataset:\n",
        "  output_index, outputs = mirrored_strategy.run(predict, args=(index, inputs))\n",
        "  indices = list(mirrored_strategy.experimental_local_results(output_index))\n",
        "  rindices = []\n",
        "  for a in indices:\n",
        "    rindices.extend(a.numpy())\n",
        "  outputs = list(mirrored_strategy.experimental_local_results(outputs))\n",
        "  routputs = []\n",
        "  for a in outputs:\n",
        "    routputs.extend(a.numpy())\n",
        "  for i, value in zip(rindices, routputs):\n",
        "    result[i] = value\n",
        "\n",
        "print(result)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
            "{0: 0, 1: 2, 2: 4, 3: 6, 4: 8, 5: 10, 6: 12, 7: 14, 8: 16, 9: 18, 10: 20, 11: 22, 12: 24, 13: 26, 14: 28, 15: 30, 16: 32, 17: 34, 18: 36, 19: 38, 20: 40, 21: 42, 22: 44, 23: 46}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpPzP9DUiAjb"
      },
      "source": [
        "## Using raw tensors or inputs from a generator \n",
        "\n",
        "---- Use experimental_distribute_values_from_function for arbitrary tensor inputs: To pass the tensor values, use experimental_distribute_values_from_function to construct tf.distribute.DistributedValues from raw tensors.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCc7ayvcglYW",
        "outputId": "a5c89ac9-149b-4487-d619-0c3a66a55c0a"
      },
      "source": [
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "worker_devices = mirrored_strategy.extended.worker_devices\n",
        "\n",
        "def value_fn(ctx):\n",
        "  return tf.constant(1.0)\n",
        "\n",
        "distributed_values = mirrored_strategy.experimental_distribute_values_from_function(value_fn)\n",
        "for _ in range(4):\n",
        "  result = mirrored_strategy.run(lambda x:x, args=(distributed_values,))\n",
        "  print(result)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "tf.Tensor(1.0, shape=(), dtype=float32)\n",
            "tf.Tensor(1.0, shape=(), dtype=float32)\n",
            "tf.Tensor(1.0, shape=(), dtype=float32)\n",
            "tf.Tensor(1.0, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgLXLvS3kmJD"
      },
      "source": [
        "Use tf.data.Dataset.from_generator if your input is from a generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM_jW_VVj5s9",
        "outputId": "8bd66857-2037-4769-e8ce-f532d8b04d07"
      },
      "source": [
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "def input_gen():\n",
        "  while True:\n",
        "    yield np.random.rand(4)\n",
        "\n",
        "dataset = tf.data.Dataset.from_generator(\n",
        "    input_gen, output_types = (tf.float32), output_shapes = tf.TensorShape([4])\n",
        ")\n",
        "\n",
        "dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)\n",
        "iterator = iter(dist_dataset)\n",
        "for _ in range(4):\n",
        "  mirrored_strategy.run(lambda x: x, args = (next(iterator),))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}