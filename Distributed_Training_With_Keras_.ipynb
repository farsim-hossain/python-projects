{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Distributed Training With Keras .ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMqffyj/+6GqyIIe0iCoWFO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e0f0a4712a284ee595db8bcf90e81471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ca950363f84a490aa3178db5b4d56320",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_503b668ae0a6400f827e17cecf04ee2a",
              "IPY_MODEL_1fb40836362548ffa27d0b65c7875860"
            ]
          }
        },
        "ca950363f84a490aa3178db5b4d56320": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "503b668ae0a6400f827e17cecf04ee2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ffbadf6909cc4f4b985809c6c69f616a",
            "_dom_classes": [],
            "description": "Dl Completed...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f949480369134972bee2c7045a4ecef8"
          }
        },
        "1fb40836362548ffa27d0b65c7875860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4594f48008df4bf4bc5ed76922131174",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [00:00&lt;00:00,  5.23 file/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b7ecb184383845e2970ddf313feb922f"
          }
        },
        "ffbadf6909cc4f4b985809c6c69f616a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f949480369134972bee2c7045a4ecef8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4594f48008df4bf4bc5ed76922131174": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b7ecb184383845e2970ddf313feb922f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87rG8vgrdVKU"
      },
      "source": [
        "tf.distribute.Strategy API provides an abstraction for distruting the training across multiple processing units. The goal is to allow users to enable distributed training using existing models and training code, with minimal changes.\n",
        "\n",
        "This tutorial uses the tf.distribute.MirroredStrategy, which does in-graph replication with synchronous training on many GPUs on one machine. Essentially, it copies all of the model's variables to each processor. Then, it uses all-reduce to combine the gradients from all processors and applies the combined value to all copies of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NhYDZyNcEHY",
        "outputId": "e1e3f4b9-866c-4592-f097-e01b634e745a"
      },
      "source": [
        "import tensorflow_datasets as tfds \n",
        "import tensorflow as tf\n",
        "import os \n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc2bfbiJeXhi"
      },
      "source": [
        "Download the MNIST dataset and load it from TensorFlow Datasets. This returns a dataset in tf.data format. Setting with_info to True includes the metadata for the entire dataset, which is being saved here to info. Among other things, this metadata object includes the number of train and test examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233,
          "referenced_widgets": [
            "e0f0a4712a284ee595db8bcf90e81471",
            "ca950363f84a490aa3178db5b4d56320",
            "503b668ae0a6400f827e17cecf04ee2a",
            "1fb40836362548ffa27d0b65c7875860",
            "ffbadf6909cc4f4b985809c6c69f616a",
            "f949480369134972bee2c7045a4ecef8",
            "4594f48008df4bf4bc5ed76922131174",
            "b7ecb184383845e2970ddf313feb922f"
          ]
        },
        "id": "2ldEAZcQeNgD",
        "outputId": "6fcad108-7ada-4a3c-aa34-7c504231b315"
      },
      "source": [
        "datasets, info = tfds.load(name = 'mnist', with_info= True, as_supervised= True)\n",
        "mnist_train, mnist_test = datasets['train'], datasets['test']"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead pass\n",
            "`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0f0a4712a284ee595db8bcf90e81471",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Dl Completed...', max=4.0, style=ProgressStyle(descriptio…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJCwlYJCfSth"
      },
      "source": [
        "We need to create a MirroredStrategy object "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mb1bUuN5fKDx",
        "outputId": "a92fdac7-42d2-4770-cd2f-712970dde4ec"
      },
      "source": [
        "strategy = tf.distribute.MirroredStrategy()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx9elaM_fgdR",
        "outputId": "6082b6bd-1c03-40cd-87e3-b75e78c0f00c"
      },
      "source": [
        "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of devices: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLBYElRLf5ar"
      },
      "source": [
        "Multiple GPU training models allows us to add extra computing power by increasing the batch size. In general, we will use the largest batch size that fits the GPU memory and tune the learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9nPG6TWfrXR"
      },
      "source": [
        "num_train_examples = info.splits['train'].num_examples \n",
        "num_test_examples = info.splits['test'].num_examples\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "BATCH_SIZE_PER_REPLICA = 64 \n",
        "BATCH_SIZE = BATCH_SIZE_PER_REPLICA*strategy.num_replicas_in_sync"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eV3tIcqhh2_"
      },
      "source": [
        "Pixel values, which are 0-255, have to be normalized to the 0-1 range. Define this scale in a function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAcEyQcqgxWz"
      },
      "source": [
        "def scale(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image /= 255 \n",
        "\n",
        "  return image, label"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVn4rXYpiBTf"
      },
      "source": [
        "Apply this function to the training and test data, shuffle the training data, and batch it for training. Notice we are also keeping an in-memory cache of the training data to improve performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5MtzHQGh1wd"
      },
      "source": [
        "train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RZqiyd5ify5"
      },
      "source": [
        "Now we will create the model and use our defined 'Strategy' object that uses distributed training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xOwFbzBidnR"
      },
      "source": [
        "with strategy.scope():\n",
        "  model = tf.keras.Sequential([\n",
        "                               tf.keras.layers.Conv2D(32,3,activation='relu', input_shape = (28,28,1)),\n",
        "                               tf.keras.layers.MaxPooling2D(),\n",
        "                               tf.keras.layers.Flatten(),\n",
        "                               tf.keras.layers.Dense(64, activation= 'relu'),\n",
        "                               tf.keras.layers.Dense(10)\n",
        "                          \n",
        "  ])\n",
        "\n",
        "  model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits= True),\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8UT6QNLjYuR"
      },
      "source": [
        "## Define the callbacks\n",
        "The callbacks used here are:\n",
        "\n",
        "TensorBoard: This callback writes a log for TensorBoard which allows you to visualize the graphs.\n",
        "Model Checkpoint: This callback saves the model after every epoch.\n",
        "Learning Rate Scheduler: Using this callback, you can schedule the learning rate to change after every epoch/batch.\n",
        "\n",
        "For illustrative purposes, add a print callback to display the learning rate in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6q-8HaYkyZ9"
      },
      "source": [
        "# Define the checkpoint directory to store the checkpoints\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "\n",
        "# name of the checkpoint files \n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTStVzkPm1qS"
      },
      "source": [
        "Learning rate need to be scheduled and decayed because not one learning rate fits the whole process. Too small LR may result the model to learn nothing, too big LR may result overfit. That is why we need to schedule the LR \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7Lac6wNlR1R"
      },
      "source": [
        "def decay(epoch):\n",
        "  if epoch <3 : \n",
        "    return 1e-3\n",
        "  elif epoch >= 3 and epoch < 7:\n",
        "    return 1e-4\n",
        "  else: \n",
        "    return 1e-5"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVPVYYN6nyIV"
      },
      "source": [
        "# Callback for printing the LR at the end of each epoch.\n",
        "class PrintLR(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs= None):\n",
        "    print('\\nLearning rate for epoch {} in {}'.format(epoch + 1,\n",
        "                                                      model.optimizer.lr.numpy()))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMj1qXPjolLS"
      },
      "source": [
        "callbacks = [\n",
        "             tf.keras.callbacks.TensorBoard(log_dir = './logs'),\n",
        "             tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
        "                                                save_weights_only = True),\n",
        "             tf.keras.callbacks.LearningRateScheduler(decay),\n",
        "             PrintLR()\n",
        "             \n",
        "]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTuQQ4pCsOcW"
      },
      "source": [
        "## Train and evaluate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yLfW0WNo1fQ",
        "outputId": "f52e80c7-001c-4161-db64-6c6b5e1a2456"
      },
      "source": [
        "model.fit(train_dataset, epochs= 12, callbacks=callbacks)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "938/938 [==============================] - 34s 33ms/step - loss: 0.1967 - accuracy: 0.9449\n",
            "\n",
            "Learning rate for epoch 1 in 0.0010000000474974513\n",
            "Epoch 2/12\n",
            "938/938 [==============================] - 26s 27ms/step - loss: 0.0646 - accuracy: 0.9811\n",
            "\n",
            "Learning rate for epoch 2 in 0.0010000000474974513\n",
            "Epoch 3/12\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 0.0447 - accuracy: 0.9866\n",
            "\n",
            "Learning rate for epoch 3 in 0.0010000000474974513\n",
            "Epoch 4/12\n",
            "938/938 [==============================] - 26s 27ms/step - loss: 0.0237 - accuracy: 0.9937\n",
            "\n",
            "Learning rate for epoch 4 in 9.999999747378752e-05\n",
            "Epoch 5/12\n",
            "938/938 [==============================] - 26s 27ms/step - loss: 0.0208 - accuracy: 0.9944\n",
            "\n",
            "Learning rate for epoch 5 in 9.999999747378752e-05\n",
            "Epoch 6/12\n",
            "938/938 [==============================] - 26s 27ms/step - loss: 0.0191 - accuracy: 0.9951\n",
            "\n",
            "Learning rate for epoch 6 in 9.999999747378752e-05\n",
            "Epoch 7/12\n",
            "938/938 [==============================] - 26s 28ms/step - loss: 0.0176 - accuracy: 0.9957\n",
            "\n",
            "Learning rate for epoch 7 in 9.999999747378752e-05\n",
            "Epoch 8/12\n",
            "938/938 [==============================] - 26s 28ms/step - loss: 0.0151 - accuracy: 0.9966\n",
            "\n",
            "Learning rate for epoch 8 in 9.999999747378752e-06\n",
            "Epoch 9/12\n",
            "938/938 [==============================] - 26s 28ms/step - loss: 0.0148 - accuracy: 0.9966\n",
            "\n",
            "Learning rate for epoch 9 in 9.999999747378752e-06\n",
            "Epoch 10/12\n",
            "938/938 [==============================] - 26s 28ms/step - loss: 0.0146 - accuracy: 0.9968\n",
            "\n",
            "Learning rate for epoch 10 in 9.999999747378752e-06\n",
            "Epoch 11/12\n",
            "938/938 [==============================] - 27s 28ms/step - loss: 0.0145 - accuracy: 0.9967\n",
            "\n",
            "Learning rate for epoch 11 in 9.999999747378752e-06\n",
            "Epoch 12/12\n",
            "938/938 [==============================] - 26s 28ms/step - loss: 0.0143 - accuracy: 0.9968\n",
            "\n",
            "Learning rate for epoch 12 in 9.999999747378752e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f314b028550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfGQU5fbtgdT"
      },
      "source": [
        "See how the learning rate is being changed...and checkpoints are getting saved as well. This is an amazing way of the tf workflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRIQwsdesdI5",
        "outputId": "029532f5-670c-4588-fd30-76720a115d2c"
      },
      "source": [
        "# checkpoints \n",
        "\n",
        "! ls {checkpoint_dir}"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t     ckpt_4.data-00000-of-00001\n",
            "ckpt_10.data-00000-of-00001  ckpt_4.index\n",
            "ckpt_10.index\t\t     ckpt_5.data-00000-of-00001\n",
            "ckpt_11.data-00000-of-00001  ckpt_5.index\n",
            "ckpt_11.index\t\t     ckpt_6.data-00000-of-00001\n",
            "ckpt_12.data-00000-of-00001  ckpt_6.index\n",
            "ckpt_12.index\t\t     ckpt_7.data-00000-of-00001\n",
            "ckpt_1.data-00000-of-00001   ckpt_7.index\n",
            "ckpt_1.index\t\t     ckpt_8.data-00000-of-00001\n",
            "ckpt_2.data-00000-of-00001   ckpt_8.index\n",
            "ckpt_2.index\t\t     ckpt_9.data-00000-of-00001\n",
            "ckpt_3.data-00000-of-00001   ckpt_9.index\n",
            "ckpt_3.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipZX2h-wt0_k"
      },
      "source": [
        "To see how the model perform, load the latest checkpoint and call evaluate on the test data.\n",
        "\n",
        "Call evaluate as before using appropriate datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wD7Gty5YtuCB",
        "outputId": "07c3d2e8-f033-4848-dea2-4fcfc840febe"
      },
      "source": [
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "eval_loss, eval_acc = model.evaluate(eval_dataset)\n",
        "\n",
        "print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 4s 15ms/step - loss: 0.0389 - accuracy: 0.9872\n",
            "Eval loss: 0.038853537291288376, Eval Accuracy: 0.9872000217437744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kN-TBh8_uz_p"
      },
      "source": [
        "We can see the Tensorboard logs at the terminal. Lets download and view "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNR060esurVt",
        "outputId": "9e6ca39d-b247-4172-a884-1e778fbdd28f"
      },
      "source": [
        "! tensorboard --logdir = path/to/log-directory"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-07 06:51:26.610371: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "usage: tensorboard [-h] [--helpfull] [--logdir PATH] [--logdir_spec PATH_SPEC]\n",
            "                   [--host ADDR] [--bind_all] [--port PORT]\n",
            "                   [--reuse_port BOOL] [--load_fast {false,auto,true}]\n",
            "                   [--extra_data_server_flags EXTRA_DATA_SERVER_FLAGS]\n",
            "                   [--grpc_creds_type {local,ssl,ssl_dev}]\n",
            "                   [--grpc_data_provider PORT] [--purge_orphaned_data BOOL]\n",
            "                   [--db URI] [--db_import] [--inspect] [--version_tb]\n",
            "                   [--tag TAG] [--event_file PATH] [--path_prefix PATH]\n",
            "                   [--window_title TEXT] [--max_reload_threads COUNT]\n",
            "                   [--reload_interval SECONDS] [--reload_task TYPE]\n",
            "                   [--reload_multifile BOOL]\n",
            "                   [--reload_multifile_inactive_secs SECONDS]\n",
            "                   [--generic_data TYPE]\n",
            "                   [--samples_per_plugin SAMPLES_PER_PLUGIN]\n",
            "                   [--whatif-use-unsafe-custom-prediction YOUR_CUSTOM_PREDICT_FUNCTION.py]\n",
            "                   [--whatif-data-dir PATH]\n",
            "                   {serve,dev} ...\n",
            "tensorboard: error: invalid choice: 'path/to/log-directory' (choose from 'serve', 'dev')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vq-EF13yvE-y",
        "outputId": "e9589eba-b0f1-41c6-84e6-d0366c872751"
      },
      "source": [
        "! ls -sh ./logs"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4.0K\n",
            "4.0K train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFys5omYvXbI"
      },
      "source": [
        "# Exporting the model \n",
        "\n",
        "path = 'saved_model/'\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PiUr1tYvhoc",
        "outputId": "d8edac40-2771-409e-94e7-efe8078ac61c"
      },
      "source": [
        "model.save(path, save_format = 'tf')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIkDcyU3voAF",
        "outputId": "95db7c77-bb8a-4334-d0e7-fb1507ec02d7"
      },
      "source": [
        "# Now load the model without 'strategy'\n",
        "unreplicated_model = tf.keras.models.load_model(path)\n",
        "unreplicated_model.compile(\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer = tf.keras.optimizers.Adam(),\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "eval_loss, eval_acc = unreplicated_model.evaluate(eval_dataset)\n",
        "\n",
        "print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 2s 10ms/step - loss: 0.0389 - accuracy: 0.9872\n",
            "Eval loss: 0.038853537291288376, Eval Accuracy: 0.9872000217437744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe8Yevgfw2nt"
      },
      "source": [
        "We can also load the model to train with distributed learning. = strategy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGS2hFtUwtLR",
        "outputId": "b04da9d6-a8ba-4d4c-97a2-9f5d8969c131"
      },
      "source": [
        "with strategy.scope():\n",
        "  replicated_model = tf.keras.models.load_model(path)\n",
        "  replicated_model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                           optimizer = tf.keras.optimizers.Adam(),\n",
        "                           metrics = ['accuracy'])\n",
        "  \n",
        "  eval_loss, eval_acc = replicated_model.evaluate(eval_dataset)\n",
        "  print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 3s 11ms/step - loss: 0.0389 - accuracy: 0.9872\n",
            "Eval loss: 0.038853537291288376, Eval Accuracy: 0.9872000217437744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J7Hksuvxws3"
      },
      "source": [
        "Although there was not much difference when trained with distributed learning, I believe the difference will be much higher if dealth with bigger datasets."
      ]
    }
  ]
}